{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95631e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb4c4319",
   "metadata": {},
   "source": [
    "# 1) Write a python program to display all the header tags from wikipedia.org.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec421015",
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"https://www.wikipedia.org/\"\n",
    "page=requests.get(url)\n",
    "page\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6434a42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup=BeautifulSoup(page.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da54a102",
   "metadata": {},
   "outputs": [],
   "source": [
    "#list of header tags\n",
    "#d_all('h1',class_=\"mw-parser-outputr\").find('span' ,class_=\"central-textlogo__image sprite svg-Wikipedia_wordmark\").get_text()\n",
    "#[class=\"mp-h2\"]\n",
    "header_tags=['h1','h2' ,'h3']\n",
    "for i in header_tags:\n",
    "    \n",
    "    header =[]\n",
    "    header =soup.find_all(i)\n",
    "    j=0\n",
    "    for k  in header:\n",
    "        j=j+1\n",
    "        if(j==1):\n",
    "            print(i,'Tag Header content is :-')\n",
    "        print(k.get_text())\n",
    "    print('-------------------')\n",
    "\n",
    "                       \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c73bf3",
   "metadata": {},
   "source": [
    "# 2. Write a python program to display IMDB’s Top rated 100 movies’ data (i.e. name, rating, year of release) and make data frame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012fe68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"https://www.imdb.com/chart/top/?ref_=nv_mv_250\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1223e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "page=requests.get(url)\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f7bb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup=BeautifulSoup(page.text,'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9f1320",
   "metadata": {},
   "outputs": [],
   "source": [
    "#soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74aa5aa5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data=soup.find('tbody',class_='lister-list')\n",
    "#data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cabf213",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data=data.find_all('tr')\n",
    "#data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d07fb61",
   "metadata": {},
   "outputs": [],
   "source": [
    "title=[]\n",
    "rating=[]\n",
    "year_of_release=[]\n",
    "\n",
    "for movie in data:\n",
    "    \n",
    "     for movie in data:\n",
    "\n",
    "        title.append(movie.find('td',class_=\"titleColumn\").find('a').get_text())\n",
    "\n",
    "        rating.append(float(movie.find('td',class_='ratingColumn imdbRating').find('strong').get_text()))\n",
    "\n",
    "        year_of_release.append(movie.find('td',class_=\"titleColumn\").find('span',class_='secondaryInfo').get_text())\n",
    "\n",
    " #dict. formation\n",
    "data={'Title':title ,\n",
    "      'Ratings':rating,\n",
    "      'Year of Release':year_of_release}\n",
    "    \n",
    "        \n",
    "    # Making movies dataframe\n",
    "movies_df= pd.DataFrame(data)  \n",
    "movies_df\n",
    "\n",
    "    #Sorting data to get rating descending order \n",
    "df=movies_df.sort_values(by=['Ratings'] ,ascending=False)\n",
    "\n",
    "    #displaying top 100 movies data\n",
    "Top_Hundread_Movies_df=df.head(100)\n",
    "Top_Hundread_Movies_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5369c5c3",
   "metadata": {},
   "source": [
    "# *** Using Function extracting Top 100 Movies data ***\n",
    "\n",
    "2. Write a python program to display IMDB’s Top rated 100 movies’ data (i.e. name, rating, year of release) and make data frame.\n",
    "\n",
    "3. Write a python program to display IMDB’s Top rated 100 Indian movies’ data (i.e. name, rating, year of release) and make data frame.¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806dd33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getting_Hundred_top_rated_movie_data(url):\n",
    "    page=requests.get(url)\n",
    "    page\n",
    "    soup=BeautifulSoup(page.text,'html.parser')\n",
    "    data=soup.find('tbody',class_='lister-list')\n",
    "    data\n",
    "    data=data.find_all('tr')\n",
    "    data\n",
    "    title=[]\n",
    "    rating=[]\n",
    "    year_of_release=[]\n",
    "\n",
    "    for movie in data:\n",
    "\n",
    "        title.append(movie.find('td',class_=\"titleColumn\").find('a').get_text())\n",
    "\n",
    "        rating.append(float(movie.find('td',class_='ratingColumn imdbRating').find('strong').get_text()))\n",
    "\n",
    "        year_of_release.append(movie.find('td',class_=\"titleColumn\").find('span',class_='secondaryInfo').get_text())\n",
    "\n",
    "    #dict. formation\n",
    "    data={'Title':title ,\n",
    "           'Ratings':rating,\n",
    "          'Year of Release':year_of_release}\n",
    "    \n",
    "        \n",
    "    # Making movies dataframe\n",
    "    movies_df= pd.DataFrame(data)  \n",
    "    movies_df\n",
    "\n",
    "    #Sorting data to get rating descending order \n",
    "    df=movies_df.sort_values(by=['Ratings'] ,ascending=False)\n",
    "\n",
    "    #displaying top 100 movies data\n",
    "    Top_Hundred_Movies_df=df.head(100)\n",
    "    Top_Hundred_Movies_df\n",
    "\n",
    "    return Top_Hundred_Movies_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "425c44aa",
   "metadata": {},
   "source": [
    "# 2. Extracting IMDB’s Top rated 100 movies calling function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1f374f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"IMDB’s Top rated 100 movies :\")\n",
    "movie_data= getting_Hundred_top_rated_movie_data(\"https://www.imdb.com/chart/top/?ref_=nv_mv_250\") \n",
    "movie_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28407e69",
   "metadata": {},
   "source": [
    "# 3. Extracting IMDB’s Top rated 100 Indian movies by calling function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9781231",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting \n",
    "print(\"IMDB’s Top rated 100 Indian movies :\")\n",
    "movie_dict= getting_Hundred_top_rated_movie_data(\"https://www.imdb.com/india/top-rated-indian-movies/?sort=nv,desc&mode=simple&page=1\") \n",
    "movie_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf5f8a5",
   "metadata": {},
   "source": [
    "# 4) Write a python program to scrape product name, price and discounts from https://meesho.com/bags\u0002ladies/pl/p7vbp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a80adb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ItemText(ls):\n",
    "    for i in ls : \n",
    "        if(ls==name1):\n",
    "            name.append(i.get_text())\n",
    "           \n",
    "        elif ls==price1 :\n",
    "            price.append(i.get_text())\n",
    "       \n",
    "        else:\n",
    "            discount.append(i.get_text())\n",
    "           \n",
    "\n",
    "url = 'https://meesho.com/bags\u0002ladies/pl/p7vbp'\n",
    "page= requests.get(url)\n",
    "\n",
    "soup=BeautifulSoup(page.content)\n",
    "\n",
    "# Making blank lists for name , price , discount \n",
    "name = []\n",
    "price = []\n",
    "discount =[]\n",
    "Item_details = {}\n",
    "\n",
    "# Extracting product names\n",
    "name1 = soup.find_all('p', class_='Text__StyledText-sc-oo0kvp-0 bWSOET NewProductCard__ProductTitle_Desktop-sc-j0e7tu-4 cQhePS NewProductCard__ProductTitle_Desktop-sc-j0e7tu-4 cQhePS')\n",
    "\n",
    "# Extracting Prices\n",
    "price1 = soup.find_all('h5' , class_='Text__StyledText-sc-oo0kvp-0 hiHdyy')\n",
    "\n",
    "# Extracting Discount\n",
    "discount1 = soup.find_all('p',class_='Text__StyledText-sc-oo0kvp-0 fCJVtz NewProductCard__DiscountTextParagraph-sc-j0e7tu-16 kmYsnm NewProductCard__DiscountTextParagraph-sc-j0e7tu-16 kmYsnm')\n",
    "\n",
    "# calling the function to append items in lists\n",
    "get_ItemText(name1)\n",
    "get_ItemText(price1)\n",
    "get_ItemText(discount1)\n",
    "\n",
    "#MAking Item Dictionary\n",
    "Item_details ={'Product Name ' : name ,\n",
    "               'Price' : price ,\n",
    "                'Discount' :discount}\n",
    " # Making Datframe of Item Details\n",
    "df=pd.DataFrame(Item_details)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad8b8b3",
   "metadata": {},
   "source": [
    "# 5) Write a python program to scrape cricket rankings from icc-cricket.com. You have to scrape:\n",
    "a) Top 10 ODI teams in men’s cricket along with the records for matches, points and rating.\n",
    "b) Top 10 ODI Batsmen along with the records of their team and rating.\n",
    "c) Top 10 ODI bowlers along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "36136ae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 ODI teams in men’s cricket along with the records for matches, points and rating.\n",
      "  \n",
      "Team_ranking       Team_name Matches Points Ratings\n",
      "           1  New Zealand NZ      17  2,054     121\n",
      "           2     England ENG      32  3,793     119\n",
      "           3   Australia AUS      28  3,244     116\n",
      "           4       India IND      38  4,162     110\n",
      "           5 South Africa SA      28  2,943     105\n",
      "           6    Pakistan PAK      27  2,524      93\n",
      "           7  Bangladesh BAN      33  2,988      91\n",
      "           8    Sri Lanka SL      35  2,835      81\n",
      "           9  West Indies WI      36  2,788      77\n",
      "          10 Afghanistan AFG      23  1,562      68\n"
     ]
    }
   ],
   "source": [
    "# 5.a) Top 10 ODI teams in men’s cricket along with the records for matches, points and rating.\n",
    "\n",
    "team_details={'Team_ranking' :[],\n",
    "               'Team_name' :[],\n",
    "                'Matches' :[],\n",
    "                'Points' :[],\n",
    "                'Ratings' :[]}\n",
    "#function call\n",
    "print(\"Top 10 ODI teams in men’s cricket along with the records for matches, points and rating.\")\n",
    "print(\"  \")\n",
    "url = 'https://www.icc-cricket.com/rankings/mens/team-rankings/odi'\n",
    "\n",
    "\n",
    "page= requests.get(url)\n",
    "soup=BeautifulSoup(page.text, 'html.parser')\n",
    "\n",
    "ranking_table= soup.find('table' , class_='table')\n",
    "    #print(ranking_table)\n",
    "\n",
    "\n",
    "for rank in ranking_table.find_all('tbody'):\n",
    "    rows = rank.find_all('tr')\n",
    "\n",
    "    #selecting top 10 records only to display by rows[0:10]\n",
    "    for row in rows[0:10]:\n",
    "\n",
    "            #extracting all columns\n",
    "        team_ranking= row.find_all('td')\n",
    "        \n",
    "            #strip() to remove extra spaces in string\n",
    "        cols=[x.text.strip() for x in team_ranking] \n",
    "        \n",
    "        #adding data to dictionary\n",
    "        team_details['Team_ranking'].append(cols[0])\n",
    "        #replacing \\n in name by space\n",
    "        team_details['Team_name'].append((cols[1]).replace('\\n' ,' '))\n",
    "        team_details['Matches'].append(cols[2])\n",
    "        team_details['Points'].append(cols[3])\n",
    "        team_details['Ratings'].append(cols[4])\n",
    "\n",
    "        #print(team_details)\n",
    "df=pd.DataFrame(team_details )\n",
    "#to print dataframe without index\n",
    "print(df.to_string(index=False))\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "436cde38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 ODI Batsmen along with the records of their team and rating.\n",
      "   \n",
      "  POS                 PLAYER TEAM RATING           CAREER BEST RATING\n",
      "0   1             Babar Azam  PAK    873    873 v England, 13/07/2021\n",
      "1   2            Virat Kohli  IND    811    911 v England, 12/07/2018\n",
      "2   3           Rohit Sharma  IND    791  885 v Sri Lanka, 06/07/2019\n",
      "3   4        Quinton de Kock   SA    783  813 v Sri Lanka, 10/03/2019\n",
      "4   5            Aaron Finch  AUS    779    798 v England, 25/06/2019\n",
      "5   6         Jonny Bairstow  ENG    775      796 v India, 26/03/2021\n",
      "6   7           David Warner  AUS    762   880 v Pakistan, 26/01/2017\n",
      "7   8  Rassie van der Dussen   SA    750      750 v India, 23/01/2022\n",
      "8   9           Fakhar Zaman  PAK    741    779 v England, 08/07/2021\n",
      "9  10               Joe Root  ENG    740  824 v Sri Lanka, 13/10/2018\n"
     ]
    }
   ],
   "source": [
    "#\"5.b) Top 10 ODI Batsmen along with the records of their team and rating.\n",
    "print(\"Top 10 ODI Batsmen along with the records of their team and rating.\")\n",
    "print(\"   \")\n",
    "\n",
    "url = 'https://www.icc-cricket.com/rankings/mens/player-rankings/ODI/batting'\n",
    "bat= requests.get(url)\n",
    "\n",
    "Batsman_details={'POS' :[],\n",
    "               'PLAYER' :[],\n",
    "                'TEAM' :[],\n",
    "                'RATING' :[],\n",
    "                'CAREER BEST RATING' :[]}\n",
    "\n",
    "\n",
    "soup=BeautifulSoup(bat.text, 'html.parser')\n",
    "\n",
    "data=soup.find('table',class_='table')\n",
    "rows=data.find_all('tr')\n",
    "for row in rows[1:11]:\n",
    "    player_ranking = row.find_all('td')\n",
    "    cols=[x.text.strip() for x in player_ranking]\n",
    " \n",
    "    Batsman_details['POS'].append(cols[0])\n",
    "                                  \n",
    "    Batsman_details['PLAYER'].append(cols[1])\n",
    "    Batsman_details['TEAM'].append(cols[2])\n",
    "    Batsman_details['RATING'].append(cols[3])\n",
    "    Batsman_details['CAREER BEST RATING'].append(cols[4])\n",
    "    \n",
    "df=pd.DataFrame(Batsman_details)\n",
    "\n",
    "## to format string 1\\n\\n\\n --> 1 \n",
    "\n",
    "df[\"POS\"]=df[\"POS\"].str[:2]\n",
    "df[\"POS\"]=df[\"POS\"].replace('\\n','',regex=True) \n",
    "print(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "2ca1ee6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>POS</th>\n",
       "      <th>PLAYER</th>\n",
       "      <th>TEAM</th>\n",
       "      <th>RATING</th>\n",
       "      <th>CAREER BEST RATING</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Trent Boult</td>\n",
       "      <td>NZ</td>\n",
       "      <td>737</td>\n",
       "      <td>770 v West Indies, 22/06/2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Josh Hazlewood</td>\n",
       "      <td>AUS</td>\n",
       "      <td>709</td>\n",
       "      <td>733 v England, 26/01/2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Chris Woakes</td>\n",
       "      <td>ENG</td>\n",
       "      <td>700</td>\n",
       "      <td>711 v Sri Lanka, 04/07/2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Matt Henry</td>\n",
       "      <td>NZ</td>\n",
       "      <td>691</td>\n",
       "      <td>691 v Bangladesh, 26/03/2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>Mujeeb Ur Rahman</td>\n",
       "      <td>AFG</td>\n",
       "      <td>681</td>\n",
       "      <td>712 v Ireland, 24/01/2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>Jasprit Bumrah</td>\n",
       "      <td>IND</td>\n",
       "      <td>679</td>\n",
       "      <td>841 v West Indies, 01/11/2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>Mehedi Hasan</td>\n",
       "      <td>BAN</td>\n",
       "      <td>675</td>\n",
       "      <td>725 v Sri Lanka, 25/05/2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>Mitchell Starc</td>\n",
       "      <td>AUS</td>\n",
       "      <td>652</td>\n",
       "      <td>783 v New Zealand, 29/03/2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>Rashid Khan</td>\n",
       "      <td>AFG</td>\n",
       "      <td>650</td>\n",
       "      <td>806 v Pakistan, 21/09/2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>Andy McBrine</td>\n",
       "      <td>IRE</td>\n",
       "      <td>646</td>\n",
       "      <td>646 v West Indies, 16/01/2022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   POS            PLAYER TEAM  RATING             CAREER BEST RATING\n",
       "1    1       Trent Boult    NZ    737  770 v West Indies, 22/06/2019\n",
       "2    2    Josh Hazlewood   AUS    709      733 v England, 26/01/2018\n",
       "3    3      Chris Woakes   ENG    700    711 v Sri Lanka, 04/07/2021\n",
       "4    4        Matt Henry    NZ    691   691 v Bangladesh, 26/03/2021\n",
       "5    5  Mujeeb Ur Rahman   AFG    681      712 v Ireland, 24/01/2021\n",
       "6    6    Jasprit Bumrah   IND    679  841 v West Indies, 01/11/2018\n",
       "7    7      Mehedi Hasan   BAN    675    725 v Sri Lanka, 25/05/2021\n",
       "8    8    Mitchell Starc   AUS    652  783 v New Zealand, 29/03/2015\n",
       "9    9       Rashid Khan   AFG    650     806 v Pakistan, 21/09/2018\n",
       "10  10      Andy McBrine   IRE    646  646 v West Indies, 16/01/2022"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#5.c)\n",
    "\n",
    "url = 'https://www.icc-cricket.com/rankings/mens/player-rankings/odi/bowling'\n",
    "\n",
    "\n",
    "page= requests.get(url)\n",
    "soup=BeautifulSoup(page.text, 'html.parser')\n",
    "table_body =soup.find('table')\n",
    "row_data=[]\n",
    "header_data=[]\n",
    "\n",
    "for row in table_body.find_all('tr'):\n",
    "    cols=row.find_all('td')\n",
    "    col=[ele.text.strip() for ele in cols]\n",
    "\n",
    "    row_data.append(col)\n",
    "for headers in soup.find_all('th'):\n",
    "    header=[headers.text.strip() ]\n",
    "    header_data.append(header)\n",
    "\n",
    "#ValueError: 1 columns passed, passed data had 5 columns getting this\n",
    "#df=pd.DataFrame(row_data,columns=header_data) \n",
    "\n",
    "df=pd.DataFrame(row_data,columns=['POS','PLAYER','TEAM ','RATING','CAREER BEST RATING'])\n",
    "df[\"POS\"]=df[\"POS\"].str[:2]\n",
    "df[\"POS\"]=df[\"POS\"].replace('\\n','',regex=True) \n",
    "df=df.dropna()\n",
    "df.head(10)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "51ed268b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "273d61fe",
   "metadata": {},
   "source": [
    "# 6) Write a python program to scrape cricket rankings from icc-cricket.com. You have to scrape:\n",
    "a) Top 10 ODI teams in women’s cricket along with the records for matches, points and rating.\n",
    "b) Top 10 women’s ODI Batting players along with the records of their team and rating.\n",
    "c) Top 10 women’s ODI all-rounder along with the records of their team and rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "0e72dc78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pos</th>\n",
       "      <th>Team</th>\n",
       "      <th>Matches</th>\n",
       "      <th>Points</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Australia  AUS</td>\n",
       "      <td>20</td>\n",
       "      <td>3,263</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>South Africa  SA</td>\n",
       "      <td>21</td>\n",
       "      <td>2,580</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>England  ENG</td>\n",
       "      <td>21</td>\n",
       "      <td>2,474</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>India  IND</td>\n",
       "      <td>22</td>\n",
       "      <td>2,221</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>New Zealand  NZ</td>\n",
       "      <td>24</td>\n",
       "      <td>2,342</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>Bangladesh  BAN</td>\n",
       "      <td>5</td>\n",
       "      <td>475</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>West Indies  WI</td>\n",
       "      <td>21</td>\n",
       "      <td>1,801</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>Pakistan  PAK</td>\n",
       "      <td>19</td>\n",
       "      <td>1,304</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>Ireland  IRE</td>\n",
       "      <td>5</td>\n",
       "      <td>240</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>Sri Lanka  SL</td>\n",
       "      <td>5</td>\n",
       "      <td>233</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pos              Team Matches Points Rating\n",
       "1    1    Australia  AUS      20  3,263    163\n",
       "2    2  South Africa  SA      21  2,580    123\n",
       "3    3      England  ENG      21  2,474    118\n",
       "4    4        India  IND      22  2,221    101\n",
       "5    5   New Zealand  NZ      24  2,342     98\n",
       "6    6   Bangladesh  BAN       5    475     95\n",
       "7    7   West Indies  WI      21  1,801     86\n",
       "8    8     Pakistan  PAK      19  1,304     69\n",
       "9    9      Ireland  IRE       5    240     48\n",
       "10  10     Sri Lanka  SL       5    233     47"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#6.a) Top 10 ODI teams in women’s cricket along with the records for matches, points and rating.\n",
    "url='https://www.icc-cricket.com/rankings/womens/team-rankings/odi'\n",
    "page= requests.get(url)\n",
    "soup = BeautifulSoup(page.text, \"html.parser\")\n",
    "table_body =soup.find('table')\n",
    "row_data=[]\n",
    "header_data=[]\n",
    "i=0\n",
    "for row in table_body.find_all('tr'):\n",
    "    cols=row.find_all('td')\n",
    "    col=[ele.text.strip() for ele in cols]\n",
    "    \n",
    "    \n",
    "    row_data.append(col)\n",
    "for headers in soup.find_all('th'):\n",
    "    header=[headers.text.strip() ]\n",
    "    header_data.append(header)\n",
    "\n",
    "#ValueError: 1 columns passed, passed data had 5 columns getting this\n",
    "#df=pd.DataFrame(row_data,columns=header_data) \n",
    "\n",
    "df=pd.DataFrame(row_data,columns=['Pos','Team','Matches','Points','Rating'])\n",
    "df=df.replace('\\n','  ',regex=True)\n",
    "df2=df.dropna()\n",
    "df2.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "f3c50820",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pos</th>\n",
       "      <th>Player</th>\n",
       "      <th>Team</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Alyssa Healy</td>\n",
       "      <td>AUS</td>\n",
       "      <td>749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2                                        (0)</td>\n",
       "      <td>Mithali Raj</td>\n",
       "      <td>IND</td>\n",
       "      <td>735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3                                            (...</td>\n",
       "      <td>Tammy Beaumont</td>\n",
       "      <td>ENG</td>\n",
       "      <td>707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4                                            (...</td>\n",
       "      <td>Meg Lanning</td>\n",
       "      <td>AUS</td>\n",
       "      <td>706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5                                            (...</td>\n",
       "      <td>Beth Mooney</td>\n",
       "      <td>AUS</td>\n",
       "      <td>705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6                                            (...</td>\n",
       "      <td>Lizelle Lee</td>\n",
       "      <td>SA</td>\n",
       "      <td>702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7                                            (...</td>\n",
       "      <td>Amy Satterthwaite</td>\n",
       "      <td>NZ</td>\n",
       "      <td>700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8                                             ...</td>\n",
       "      <td>Smriti Mandhana</td>\n",
       "      <td>IND</td>\n",
       "      <td>666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9                                            (...</td>\n",
       "      <td>Laura Wolvaardt</td>\n",
       "      <td>SA</td>\n",
       "      <td>661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10                                            ...</td>\n",
       "      <td>Ellyse Perry</td>\n",
       "      <td>AUS</td>\n",
       "      <td>661</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Pos             Player Team  \\\n",
       "0                                                   1       Alyssa Healy  AUS   \n",
       "2        2                                        (0)        Mithali Raj  IND   \n",
       "3   3                                            (...     Tammy Beaumont  ENG   \n",
       "4   4                                            (...        Meg Lanning  AUS   \n",
       "5   5                                            (...        Beth Mooney  AUS   \n",
       "6   6                                            (...        Lizelle Lee   SA   \n",
       "7   7                                            (...  Amy Satterthwaite   NZ   \n",
       "8   8                                             ...    Smriti Mandhana  IND   \n",
       "9   9                                            (...    Laura Wolvaardt   SA   \n",
       "10  10                                            ...       Ellyse Perry  AUS   \n",
       "\n",
       "   Rating  \n",
       "0     749  \n",
       "2     735  \n",
       "3     707  \n",
       "4     706  \n",
       "5     705  \n",
       "6     702  \n",
       "7     700  \n",
       "8     666  \n",
       "9     661  \n",
       "10    661  "
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#6. b) Top 10 women’s ODI Batting players along with the records of their team and rating. \n",
    "url='https://www.icc-cricket.com/rankings/womens/player-rankings/odi'\n",
    "page= requests.get(url)\n",
    "soup = BeautifulSoup(page.text, \"html.parser\")\n",
    "table_body =soup.find('table')\n",
    "row_data=[]\n",
    "header_data=[]\n",
    "\n",
    "row_data_1=[] #to save 1st palyer data\n",
    "row_data_1_rank=soup.find('span',class_='rankings-block__pos-number').text\n",
    "\n",
    "\n",
    "row_data_1_name=soup.find('div',class_='rankings-block__banner--name').text\n",
    "\n",
    "row_data_1_team=soup.find('div',class_='rankings-block__banner--nationality').text\n",
    "\n",
    "row_data_1.append(row_data_1_rank.strip())\n",
    "row_data_1.append(row_data_1_name.strip())\n",
    "team_rate=row_data_1_team.split()\n",
    "\n",
    "row_data_1.append(team_rate[0])\n",
    "row_data_1.append(team_rate[1])\n",
    "\n",
    "row_data.append(row_data_1)\n",
    "\n",
    "for row in table_body.find_all('tr'):\n",
    "    cols=row.find_all('td')\n",
    "    col=[ele.text.strip() for ele in cols]\n",
    "    \n",
    "    row_data.append(col)\n",
    "for headers in soup.find_all('th'):\n",
    "    header=[headers.text.strip() ]\n",
    "    header_data.append(header)\n",
    "\n",
    "#ValueError: 1 columns passed, passed data had 5 columns getting this\n",
    "#df=pd.DataFrame(row_data,columns=header_data) \n",
    "\n",
    "df=pd.DataFrame(row_data,columns=['Pos','Player','Team','Rating'])\n",
    "df=df.replace('\\n','  ',regex=True)\n",
    "df2=df.dropna()\n",
    "df2.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "78d1f13c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Pos           Player Team Rating\n",
      "0       1      EllysePerry  AUS    438\n",
      "2    2(0)    NatalieSciver  ENG    351\n",
      "3    3(0)    MarizanneKapp   SA    327\n",
      "4    4(1)       AmeliaKerr   NZ    312\n",
      "5    5(1)     DeeptiSharma  IND    309\n",
      "6    6(0)   KatherineBrunt  ENG    273\n",
      "7    7(0)     JessJonassen  AUS    263\n",
      "8    8(0)   StafanieTaylor   WI    262\n",
      "9    9(0)  AshleighGardner  AUS    256\n",
      "10  10(0)   HayleyMatthews   WI    254\n"
     ]
    }
   ],
   "source": [
    "#6.c) Top 10 women’s ODI all-rounder along with the records of their team and rating\n",
    "\n",
    "\n",
    "url='https://www.icc-cricket.com/rankings/womens/player-rankings/odi'\n",
    "page= requests.get(url)\n",
    "soup = BeautifulSoup(page.text, \"html.parser\")\n",
    "container=soup.find('div' , attrs={'data-title':\"ODI All-Rounder Rankings\" } )\n",
    "\n",
    "table_body =container.find('table')\n",
    "\n",
    "\n",
    "row_data=[]\n",
    "header_data=[]\n",
    "\n",
    "row_data_1=[] #to save 1st palyer dat\n",
    "\n",
    "row_data_1_rank=container.find('span',class_='rankings-block__pos-number').text\n",
    "row_data_1_name=container.find('div',class_='rankings-block__banner--name').text\n",
    "row_data_1.append(row_data_1_rank.strip())\n",
    "row_data_1.append(row_data_1_name.strip())\n",
    "\n",
    "row_data_1_team=container.find('div',class_='rankings-block__banner--nationality').text\n",
    "\n",
    "row_data_1.append(team_rate[0])\n",
    "row_data_1.append(team_rate[1])\n",
    "\n",
    "row_data.append(row_data_1)\n",
    "i=0\n",
    "for row in table_body.find_all('tr'):\n",
    "    i=i+1\n",
    "    cols=row.find_all('td')\n",
    "    col=[ele.text.strip() for ele in cols]\n",
    "    y=[]\n",
    "    for x in col:\n",
    "        if \"This player has moved up\" in x:\n",
    "            x=x.replace('This player has moved up in the rankings since the previous rankings update','')\n",
    "        elif 'This player has moved down' in x:\n",
    "            x=x.replace('This player has moved down in the rankings since the previous rankings update','')\n",
    "        y.append(x)    \n",
    "       \n",
    "    row_data.append(y)\n",
    "\n",
    "for headers in soup.find_all('th'):\n",
    "    header=[headers.text.strip()]\n",
    "    header_data.append(header)\n",
    "   \n",
    "# ValueError: 1 columns passed, passed data had 5 columns getting this\n",
    "#df=pd.DataFrame(row_data,columns=header_data) \n",
    "# del row_data[1]\n",
    "\n",
    "df=pd.DataFrame(row_data,columns=['Pos','Player','Team','Rating'])\n",
    "df=df.replace('\\n' ,\"\" ,regex=True)\n",
    "df=df.replace(' ' ,\"\" ,regex=True)\n",
    "print(df.dropna())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6263715c",
   "metadata": {},
   "source": [
    "# 7) Write a python program to scrape details of all the posts from coreyms.com. Scrape the heading, date, content\n",
    "and the code for the video from the link for the youtube video from the post."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be25ecdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "          \n",
    "\n",
    "post_details ={'Heading':[],\n",
    "                'Date':[],\n",
    "                'Content':[],\n",
    "                'Link':[]}\n",
    "url=' https://www.coreyms.com.'\n",
    "page = requests.get(url)\n",
    "soup=BeautifulSoup(page.text,'html.parser')\n",
    "\n",
    "# ={'Heading':[]}\n",
    "\n",
    "page_data=soup.find_all('header',class_=\"entry-header\")\n",
    "for x in page_data:\n",
    "#extracting heading\n",
    "    heading=x.find('h2',class_='entry-title').text\n",
    "    post_details['Heading'].append(heading)\n",
    "    \n",
    "#extracting date\n",
    "    date=x.find('time',class_='entry-time').text\n",
    "    post_details['Date'].append(date)\n",
    "\n",
    "page_content=soup.find_all('div', class_= 'entry-content')\n",
    " #to extract content\n",
    "L=0\n",
    "for i in page_content:\n",
    "    L=L+1\n",
    "    content=i.find('p').text\n",
    "    post_details['Content'].append(content)\n",
    "    \n",
    "#to extract video link\n",
    "#since 5th link is not present it shows none to skip 5th n iterate rest will have to enter blank string bcoz length of all sets has to be same in dict.\n",
    "    if(L==5):\n",
    "        link=\"\"\n",
    "        post_details['Link'].append(link)\n",
    "        continue\n",
    "    link=i.find('iframe' ,class_=\"youtube-player\").get('src')\n",
    "    post_details['Link'].append(link)\n",
    "   # print(link)\n",
    "    \n",
    "\n",
    "\n",
    "df =pd.DataFrame(post_details)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fcda600",
   "metadata": {},
   "source": [
    "# 9) Write a python program to scrape mentioned details from dineout.co.in :\n",
    "i) Restaurant name\n",
    "ii) Cuisine\n",
    "iii) Location\n",
    "iv) Ratings\n",
    "v) Image URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d42bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dineout_details ={'Restaurant name':[],\n",
    "                'Cuisine':[],\n",
    "                'Locationt':[],\n",
    "                'Ratings':[],\n",
    "                'Image URL':[]}\n",
    "url='https://www.dineout.co.in/delhi/greppo-cafe-sector-61-gurgaon-100732'\n",
    "page = requests.get(url)\n",
    "soup=BeautifulSoup(page.text,'html.parser')\n",
    "# extract name\n",
    "Restaurant_name=soup.find('div',class_=\"restnt-details_info\").find('h1').text\n",
    "print('i) Restaurantname is :',Restaurant_name)\n",
    "\n",
    "#extract Cuisines\n",
    "Cuisines=soup.find('div',class_=\"about-info d-flex\").find_all('a')\n",
    "Cuisines_offered=[]\n",
    "for cuisine in Cuisines:\n",
    "    Cuisines_offered.append(cuisine.text)\n",
    "print('ii) Cuisines offered are :',Cuisines_offered)\n",
    "\n",
    "# extract location\n",
    "loc=soup.find('div',class_='restnt-name').find_all('a')\n",
    "location=\"\"\n",
    "for x in loc[0:2]:\n",
    "    location=location+\" \"+ x.text \n",
    "print('iii) Location is : ',location)\n",
    "\n",
    "#extract ratings\n",
    "rating=soup.find('div', class_=\"cursor rest-rating rating-4_5\").text\n",
    "print(\"iv) Restaurent rating is : \" ,rating)\n",
    "\n",
    "#extract image url\n",
    "url=soup.find('img', class_=\"rdp-banner_img\").get('src')\n",
    "print(\"v) Restaurent rating is : \" ,url)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f5d8d0",
   "metadata": {},
   "source": [
    "# 10) Write a python program to scrape first 10 product details which include product name , price , Image URL from\n",
    "https://www.bewakoof.com/women-tshirts?ga_q=tshirts ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6246be86",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "product_details = {'Name':[],\n",
    "                   'Actual Price':[],\n",
    "                   'Discounted Price':[],\n",
    "                    'Image URL':[]}\n",
    "\n",
    "url='https://www.bewakoof.com/women-tshirts?ga_q=tshirts'\n",
    "page=requests.get(url)\n",
    "soup=BeautifulSoup(page.text , 'html.parser')\n",
    "\n",
    "data =soup.find_all('div',class_='productCardDetail')\n",
    "#print(data)\n",
    "img=soup.find('div', class_ ='productCardImg false')\n",
    "\n",
    "for product in data[0:11]:\n",
    "   \n",
    "#extract product name\n",
    "    name=product.find('h3')\n",
    "   \n",
    "    product_details['Name'].append(name)\n",
    "   \n",
    "\n",
    "#extract product  Actual_price\n",
    "    Actual_price=product.find('span',class_='actualPriceText').text\n",
    "    product_details['Actual Price'].append(Actual_price)\n",
    "    \n",
    "#extract product  Actual_price\n",
    "    dis_price=product.find('span',class_='discountedPriceText')\n",
    "    discounted_price =dis_price.find('b').text\n",
    "    product_details['Discounted Price'].append(discounted_price)\n",
    "    \n",
    "#extract product  Actual_price   \n",
    "img=soup.find_all('div', class_ ='productCardImg false')\n",
    "for image in img[0:11]:\n",
    "    url=image.find('img').get('src')\n",
    "    product_details['Image URL'].append(url)\n",
    "    \n",
    "df =pd.DataFrame(product_details)\n",
    "df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a09b0f61",
   "metadata": {},
   "source": [
    "# 8) Write a python program to scrape house details from mentioned URL. It should include house title, location,\n",
    "area, EMI and price from https://www.nobroker.in/ .Enter three localities which are Indira Nagar, Jayanagar, \n",
    "Rajaji Nagar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f95ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"https://www.nobroker.in/property/sale/pune/multiple?searchParam=W3sibGF0IjoxOC41OTg2NzYzLCJsb24iOjczLjc5NzgzNDc5OTk5OTk5LCJwbGFjZUlkIjoiQ2hJSnIxM1pEUnU1d2pzUmVKbWdsamR1eTZZIiwicGxhY2VOYW1lIjoiUGltcGxlIFNhdWRhZ2FyIn0seyJsYXQiOjE4LjU4NjU5NjIsImxvbiI6NzMuODEzNDQyNCwicGxhY2VJZCI6IkNoSUoweFRFaE1hNHdqc1JzcjY2TlNDbVZrYyIsInBsYWNlTmFtZSI6IlBpbXBsZSBHdXJhdiJ9LHsibGF0IjoxOC41NjAxNjQ5LCJsb24iOjczLjgwMzEzMzUsInBsYWNlSWQiOiJDaElKelVGZ09raV93anNSTFRyZjJYN2dhTmsiLCJwbGFjZU5hbWUiOiJBdW5kaCJ9XQ==&radius=2.0&type=BHK2&city=pune&locality=Pimple%20Saudagar,&locality=Pimple%20Gurav,&locality=Aundh\"\n",
    "page= requests.get(url)\n",
    "\n",
    "soup= BeautifulSoup(page.text,'html.parser')\n",
    "\n",
    "names=[name.text.strip() for name in soup.find_all('h2',class_=\"heading-6 flex items-center font-semi-bold m-0\")]\n",
    "\n",
    "locations=soup.find_all('div',class_=\"mt-0.5p overflow-hidden overflow-ellipsis whitespace-nowrap max-w-70 text-gray-light leading-4 po:mb-0 po:max-w-95\")\n",
    "location=[location.text.strip()for location in locations]\n",
    "\n",
    "\n",
    "areas=soup.find_all(itemprop=\"additionalProperty\")\n",
    "area=areas.find('div',class_=\"flex\")\n",
    "#area=[area.text.strip()for area in areas]\n",
    "#print(\"area\")\n",
    "print(area)                                            \n",
    "# ['div' id=\"roomType\"] emi"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
