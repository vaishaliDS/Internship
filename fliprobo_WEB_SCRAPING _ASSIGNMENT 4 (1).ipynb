{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98b16aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Importing selenium webdriver \n",
    "from selenium import webdriver\n",
    "\n",
    "# Importing required Exceptions which needs to handled\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "\n",
    "#Importing requests\n",
    "import requests\n",
    "\n",
    "# importing time\n",
    "import time\n",
    "\n",
    "# importing regex\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a04b1d07",
   "metadata": {},
   "source": [
    ".1. Scrape the details of most viewed videos on YouTube from Wikipedia.\n",
    "Url = https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos\n",
    "You need to find following details:\n",
    "A) Rank\n",
    "B) Name\n",
    "C) Artist\n",
    "D) Upload date\n",
    "E) Views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "faeb6410",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first connect to the webdriver\n",
    "driver= webdriver.Chrome(r\"C:\\Users\\nbson\\Downloads\\chromedriver_win32 (3)\\chromedriver.exe\")\n",
    "#connection after uploading driver in jupyter notebook\n",
    "driver=webdriver.Chrome(\"chromedriver.exe\")\n",
    "\n",
    "# Opening the homepage of Amazon.in\n",
    "url = \"https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos\"\n",
    "driver.get(url)\n",
    "\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "c23d0576",
   "metadata": {},
   "outputs": [],
   "source": [
    "Rank=[]\n",
    "Name=[]\n",
    "Artist=[]\n",
    "Upload_date=[]\n",
    "Views=[]\n",
    "\n",
    "\n",
    "td_rank=driver.find_elements_by_xpath('//table[@class=\"wikitable sortable jquery-tablesorter\"]/tbody/tr/td[1]')\n",
    "\n",
    "td_name=driver.find_elements_by_xpath('//table[@class=\"wikitable sortable jquery-tablesorter\"]/tbody/tr/td[2]')\n",
    "\n",
    "td_artist=driver.find_elements_by_xpath('//table[@class=\"wikitable sortable jquery-tablesorter\"]/tbody/tr/td[3]')\n",
    "\n",
    "td_upload_date=driver.find_elements_by_xpath('//table[@class=\"wikitable sortable jquery-tablesorter\"]/tbody/tr/td[5]')\n",
    "\n",
    "td_views=driver.find_elements_by_xpath('//table[@class=\"wikitable sortable jquery-tablesorter\"]/tbody/tr/td[4]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "d78cbbe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ****** Top 30 most-viewed YouTube videos *****\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Name</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Upload_date</th>\n",
       "      <th>Views</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.</td>\n",
       "      <td>\"Baby Shark Dance\"[3]</td>\n",
       "      <td>Pinkfong Baby Shark - Kids' Songs &amp; Stories</td>\n",
       "      <td>June 17, 2016</td>\n",
       "      <td>10.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.</td>\n",
       "      <td>\"Despacito\"[6]</td>\n",
       "      <td>Luis Fonsi</td>\n",
       "      <td>January 12, 2017</td>\n",
       "      <td>7.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.</td>\n",
       "      <td>\"Johny Johny Yes Papa\"[12]</td>\n",
       "      <td>LooLoo Kids</td>\n",
       "      <td>October 8, 2016</td>\n",
       "      <td>6.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.</td>\n",
       "      <td>\"Shape of You\"[13]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>January 30, 2017</td>\n",
       "      <td>5.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.</td>\n",
       "      <td>\"See You Again\"[15]</td>\n",
       "      <td>Wiz Khalifa</td>\n",
       "      <td>April 6, 2015</td>\n",
       "      <td>5.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.</td>\n",
       "      <td>\"Bath Song\"[20]</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>May 2, 2018</td>\n",
       "      <td>5.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.</td>\n",
       "      <td>\"Phonics Song with Two Words\"[21]</td>\n",
       "      <td>ChuChu TV</td>\n",
       "      <td>March 6, 2014</td>\n",
       "      <td>4.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.</td>\n",
       "      <td>\"Learning Colors – Colorful Eggs on a Farm\"[22]</td>\n",
       "      <td>Miroshka TV</td>\n",
       "      <td>February 27, 2018</td>\n",
       "      <td>4.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.</td>\n",
       "      <td>\"Uptown Funk\"[23]</td>\n",
       "      <td>Mark Ronson</td>\n",
       "      <td>November 19, 2014</td>\n",
       "      <td>4.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.</td>\n",
       "      <td>\"Masha and the Bear – Recipe for Disaster\"[24]</td>\n",
       "      <td>Get Movies</td>\n",
       "      <td>January 31, 2012</td>\n",
       "      <td>4.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11.</td>\n",
       "      <td>\"Gangnam Style\"[25]</td>\n",
       "      <td>Psy</td>\n",
       "      <td>July 15, 2012</td>\n",
       "      <td>4.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12.</td>\n",
       "      <td>\"Wheels on the Bus\"[30]</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>May 24, 2018</td>\n",
       "      <td>3.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13.</td>\n",
       "      <td>\"Dame Tu Cosita\"[31]</td>\n",
       "      <td>El Chombo</td>\n",
       "      <td>April 5, 2018</td>\n",
       "      <td>3.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14.</td>\n",
       "      <td>\"Sugar\"[32]</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>January 14, 2015</td>\n",
       "      <td>3.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15.</td>\n",
       "      <td>\"Roar\"[33]</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>September 5, 2013</td>\n",
       "      <td>3.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16.</td>\n",
       "      <td>\"Counting Stars\"[34]</td>\n",
       "      <td>OneRepublic</td>\n",
       "      <td>May 31, 2013</td>\n",
       "      <td>3.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17.</td>\n",
       "      <td>\"Sorry\"[35]</td>\n",
       "      <td>Justin Bieber</td>\n",
       "      <td>October 22, 2015</td>\n",
       "      <td>3.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18.</td>\n",
       "      <td>\"Thinking Out Loud\"[36]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>October 7, 2014</td>\n",
       "      <td>3.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19.</td>\n",
       "      <td>\"Axel F\"[37]</td>\n",
       "      <td>Crazy Frog</td>\n",
       "      <td>June 16, 2009</td>\n",
       "      <td>3.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20.</td>\n",
       "      <td>\"Girls Like You\"[38]</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>May 31, 2018</td>\n",
       "      <td>3.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21.</td>\n",
       "      <td>\"Faded\"[39]</td>\n",
       "      <td>Alan Walker</td>\n",
       "      <td>December 3, 2015</td>\n",
       "      <td>3.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22.</td>\n",
       "      <td>\"Dark Horse\"[40]</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>February 20, 2014</td>\n",
       "      <td>3.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23.</td>\n",
       "      <td>\"Let Her Go\"[41]</td>\n",
       "      <td>Passenger</td>\n",
       "      <td>July 25, 2012</td>\n",
       "      <td>3.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24.</td>\n",
       "      <td>\"Baa Baa Black Sheep\"[42]</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>June 25, 2018</td>\n",
       "      <td>3.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25.</td>\n",
       "      <td>\"Bailando\"[43]</td>\n",
       "      <td>Enrique Iglesias</td>\n",
       "      <td>April 11, 2014</td>\n",
       "      <td>3.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26.</td>\n",
       "      <td>\"Lean On\"[44]</td>\n",
       "      <td>Major Lazer</td>\n",
       "      <td>March 22, 2015</td>\n",
       "      <td>3.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27.</td>\n",
       "      <td>\"Shake It Off\"[45]</td>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>August 18, 2014</td>\n",
       "      <td>3.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28.</td>\n",
       "      <td>\"Perfect\"[46]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>November 9, 2017</td>\n",
       "      <td>3.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29.</td>\n",
       "      <td>\"Waka Waka (This Time for Africa)\"[47]</td>\n",
       "      <td>Shakira</td>\n",
       "      <td>June 4, 2010</td>\n",
       "      <td>3.12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                                             Name  \\\n",
       "0    1.                            \"Baby Shark Dance\"[3]   \n",
       "1    2.                                   \"Despacito\"[6]   \n",
       "2    3.                       \"Johny Johny Yes Papa\"[12]   \n",
       "3    4.                               \"Shape of You\"[13]   \n",
       "4    5.                              \"See You Again\"[15]   \n",
       "5    6.                                  \"Bath Song\"[20]   \n",
       "6    7.                \"Phonics Song with Two Words\"[21]   \n",
       "7    8.  \"Learning Colors – Colorful Eggs on a Farm\"[22]   \n",
       "8    9.                                \"Uptown Funk\"[23]   \n",
       "9   10.   \"Masha and the Bear – Recipe for Disaster\"[24]   \n",
       "10  11.                              \"Gangnam Style\"[25]   \n",
       "11  12.                          \"Wheels on the Bus\"[30]   \n",
       "12  13.                             \"Dame Tu Cosita\"[31]   \n",
       "13  14.                                      \"Sugar\"[32]   \n",
       "14  15.                                       \"Roar\"[33]   \n",
       "15  16.                             \"Counting Stars\"[34]   \n",
       "16  17.                                      \"Sorry\"[35]   \n",
       "17  18.                          \"Thinking Out Loud\"[36]   \n",
       "18  19.                                     \"Axel F\"[37]   \n",
       "19  20.                             \"Girls Like You\"[38]   \n",
       "20  21.                                      \"Faded\"[39]   \n",
       "21  22.                                 \"Dark Horse\"[40]   \n",
       "22  23.                                 \"Let Her Go\"[41]   \n",
       "23  24.                        \"Baa Baa Black Sheep\"[42]   \n",
       "24  25.                                   \"Bailando\"[43]   \n",
       "25  26.                                    \"Lean On\"[44]   \n",
       "26  27.                               \"Shake It Off\"[45]   \n",
       "27  28.                                    \"Perfect\"[46]   \n",
       "28  29.           \"Waka Waka (This Time for Africa)\"[47]   \n",
       "\n",
       "                                         Artist        Upload_date  Views  \n",
       "0   Pinkfong Baby Shark - Kids' Songs & Stories      June 17, 2016  10.53  \n",
       "1                                    Luis Fonsi   January 12, 2017   7.82  \n",
       "2                                   LooLoo Kids    October 8, 2016   6.31  \n",
       "3                                    Ed Sheeran   January 30, 2017   5.69  \n",
       "4                                   Wiz Khalifa      April 6, 2015   5.48  \n",
       "5                    Cocomelon – Nursery Rhymes        May 2, 2018   5.27  \n",
       "6                                     ChuChu TV      March 6, 2014   4.58  \n",
       "7                                   Miroshka TV  February 27, 2018   4.56  \n",
       "8                                   Mark Ronson  November 19, 2014   4.54  \n",
       "9                                    Get Movies   January 31, 2012   4.49  \n",
       "10                                          Psy      July 15, 2012   4.40  \n",
       "11                   Cocomelon – Nursery Rhymes       May 24, 2018   3.96  \n",
       "12                                    El Chombo      April 5, 2018   3.92  \n",
       "13                                     Maroon 5   January 14, 2015   3.68  \n",
       "14                                   Katy Perry  September 5, 2013   3.56  \n",
       "15                                  OneRepublic       May 31, 2013   3.56  \n",
       "16                                Justin Bieber   October 22, 2015   3.54  \n",
       "17                                   Ed Sheeran    October 7, 2014   3.44  \n",
       "18                                   Crazy Frog      June 16, 2009   3.32  \n",
       "19                                     Maroon 5       May 31, 2018   3.28  \n",
       "20                                  Alan Walker   December 3, 2015   3.27  \n",
       "21                                   Katy Perry  February 20, 2014   3.26  \n",
       "22                                    Passenger      July 25, 2012   3.21  \n",
       "23                   Cocomelon – Nursery Rhymes      June 25, 2018   3.21  \n",
       "24                             Enrique Iglesias     April 11, 2014   3.19  \n",
       "25                                  Major Lazer     March 22, 2015   3.19  \n",
       "26                                 Taylor Swift    August 18, 2014   3.16  \n",
       "27                                   Ed Sheeran   November 9, 2017   3.14  \n",
       "28                                      Shakira       June 4, 2010   3.12  "
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(len(td_rank)):\n",
    " # Extracting rank\n",
    "    try:\n",
    "        rank=td_rank[i].text     \n",
    "        Rank.append(rank)\n",
    "    except NoSuchElementException:\n",
    "        Rank.append('-') \n",
    "        \n",
    "# Extracting Name\n",
    "    try:\n",
    "        name=td_name[i].text     \n",
    "        Name.append(name)\n",
    "    except NoSuchElementException:\n",
    "        Name.append('-') \n",
    "        \n",
    "# Extracting Artist\n",
    "    try:\n",
    "        artist=td_artist[i].text     \n",
    "        Artist.append(artist)\n",
    "    except NoSuchElementException:\n",
    "        Artist.append('-')\n",
    "        \n",
    "# Extracting Upload_date\n",
    "    try:\n",
    "        upload_date=td_upload_date[i].text     \n",
    "        Upload_date.append(upload_date)\n",
    "    except NoSuchElementException:\n",
    "        Upload_date.append('-')  \n",
    "        \n",
    "# Extracting views\n",
    "    try:\n",
    "        views=td_views[i].text     \n",
    "        Views.append(views)\n",
    "    except NoSuchElementException:\n",
    "        Views.append('-')  \n",
    "        \n",
    "time.sleep(2)    \n",
    "# Make dataframe\n",
    "video_details_df = pd.DataFrame({'Rank':Rank,'Name':Name,'Artist':Artist,'Upload_date':Upload_date,'Views':Views,})\n",
    "print(\" ****** Top 30 most-viewed YouTube videos *****\\n\")\n",
    "video_details_df.iloc[0:29,:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "492b0585",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ****** Progression of the most-viewed video on YouTube *****\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Name</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Upload_date</th>\n",
       "      <th>Views</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>\"Baby Shark Dance\"[3]</td>\n",
       "      <td>Pinkfong Baby Shark - Kids' Songs &amp; Stories</td>\n",
       "      <td>7,037,500,000</td>\n",
       "      <td>November 2, 2020</td>\n",
       "      <td>June 17, 2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>\"Despacito\"[6]</td>\n",
       "      <td>Luis Fonsi</td>\n",
       "      <td>2,993,700,000</td>\n",
       "      <td>August 4, 2017</td>\n",
       "      <td>January 12, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>\"See You Again\"[15]</td>\n",
       "      <td>Wiz Khalifa</td>\n",
       "      <td>2,894,000,000</td>\n",
       "      <td>July 10, 2017</td>\n",
       "      <td>April 6, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>\"Gangnam Style\"⁂[25]</td>\n",
       "      <td>Psy</td>\n",
       "      <td>803,700,000</td>\n",
       "      <td>November 24, 2012</td>\n",
       "      <td>July 15, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>\"Baby\"*[59]</td>\n",
       "      <td>Justin Bieber</td>\n",
       "      <td>245,400,000</td>\n",
       "      <td>July 16, 2010</td>\n",
       "      <td>February 19, 2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>\"Bad Romance\"[63]</td>\n",
       "      <td>Lady Gaga</td>\n",
       "      <td>178,400,000</td>\n",
       "      <td>April 14, 2010</td>\n",
       "      <td>November 24, 2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>\"Charlie Bit My Finger\"‡[67]</td>\n",
       "      <td>HDCYT</td>\n",
       "      <td>128,900,000</td>\n",
       "      <td>October 25, 2009</td>\n",
       "      <td>May 22, 2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>\"Evolution of Dance\"[69]</td>\n",
       "      <td>Judson Laipply</td>\n",
       "      <td>118,900,000</td>\n",
       "      <td>May 2, 2009</td>\n",
       "      <td>April 6, 2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>\"Girlfriend\"‡[71][72]</td>\n",
       "      <td>RCA Records</td>\n",
       "      <td>92,600,000</td>\n",
       "      <td>July 17, 2008</td>\n",
       "      <td>February 27, 2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>\"Evolution of Dance\"[69]</td>\n",
       "      <td>Judson Laipply</td>\n",
       "      <td>78,400,000</td>\n",
       "      <td>March 15, 2008</td>\n",
       "      <td>April 6, 2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>\"Music Is My Hot Hot Sex\"‡[75]</td>\n",
       "      <td>CLARUSBARTEL72</td>\n",
       "      <td>76,600,000</td>\n",
       "      <td>March 1, 2008</td>\n",
       "      <td>April 9, 2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>\"Evolution of Dance\"*[69]</td>\n",
       "      <td>Judson Laipply</td>\n",
       "      <td>10,600,000</td>\n",
       "      <td>May 19, 2006</td>\n",
       "      <td>April 6, 2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>\"Pokemon Theme Music Video\"‡[80]</td>\n",
       "      <td>Smosh</td>\n",
       "      <td>4,300,000</td>\n",
       "      <td>March 12, 2006</td>\n",
       "      <td>November 28, 2005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>\"Myspace – The Movie\"‡[84][85]</td>\n",
       "      <td>eggtea</td>\n",
       "      <td>2,700,000</td>\n",
       "      <td>February 18, 2006</td>\n",
       "      <td>January 31, 2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>\"Phony Photo Booth\"‡[87]</td>\n",
       "      <td>mugenized</td>\n",
       "      <td>3,400,000</td>\n",
       "      <td>January 21, 2006</td>\n",
       "      <td>December 1, 2005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>\"The Chronic of Narnia Rap\"‡[89]</td>\n",
       "      <td>youtubedude</td>\n",
       "      <td>2,300,000</td>\n",
       "      <td>January 9, 2006</td>\n",
       "      <td>December 18, 2005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>\"Ronaldinho: Touch of Gold\"‡*[91]</td>\n",
       "      <td>Nikesoccer</td>\n",
       "      <td>255,000</td>\n",
       "      <td>October 31, 2005</td>\n",
       "      <td>October 21, 2005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>\"I/O Brush\"‡*[94]</td>\n",
       "      <td>larfus</td>\n",
       "      <td>247,000</td>\n",
       "      <td>October 29, 2005</td>\n",
       "      <td>October 5, 2005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>\"Me at the zoo\"[96]</td>\n",
       "      <td>jawed</td>\n",
       "      <td>1</td>\n",
       "      <td>April 23, 2005</td>\n",
       "      <td>April 23, 2005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Rank  \\\n",
       "30              \"Baby Shark Dance\"[3]   \n",
       "31                     \"Despacito\"[6]   \n",
       "32                \"See You Again\"[15]   \n",
       "33               \"Gangnam Style\"⁂[25]   \n",
       "34                        \"Baby\"*[59]   \n",
       "35                  \"Bad Romance\"[63]   \n",
       "36       \"Charlie Bit My Finger\"‡[67]   \n",
       "37           \"Evolution of Dance\"[69]   \n",
       "38              \"Girlfriend\"‡[71][72]   \n",
       "39           \"Evolution of Dance\"[69]   \n",
       "40     \"Music Is My Hot Hot Sex\"‡[75]   \n",
       "41          \"Evolution of Dance\"*[69]   \n",
       "42   \"Pokemon Theme Music Video\"‡[80]   \n",
       "43     \"Myspace – The Movie\"‡[84][85]   \n",
       "44           \"Phony Photo Booth\"‡[87]   \n",
       "45   \"The Chronic of Narnia Rap\"‡[89]   \n",
       "46  \"Ronaldinho: Touch of Gold\"‡*[91]   \n",
       "47                  \"I/O Brush\"‡*[94]   \n",
       "48                \"Me at the zoo\"[96]   \n",
       "\n",
       "                                           Name         Artist  \\\n",
       "30  Pinkfong Baby Shark - Kids' Songs & Stories  7,037,500,000   \n",
       "31                                   Luis Fonsi  2,993,700,000   \n",
       "32                                  Wiz Khalifa  2,894,000,000   \n",
       "33                                          Psy    803,700,000   \n",
       "34                                Justin Bieber    245,400,000   \n",
       "35                                    Lady Gaga    178,400,000   \n",
       "36                                        HDCYT    128,900,000   \n",
       "37                               Judson Laipply    118,900,000   \n",
       "38                                  RCA Records     92,600,000   \n",
       "39                               Judson Laipply     78,400,000   \n",
       "40                               CLARUSBARTEL72     76,600,000   \n",
       "41                               Judson Laipply     10,600,000   \n",
       "42                                        Smosh      4,300,000   \n",
       "43                                       eggtea      2,700,000   \n",
       "44                                    mugenized      3,400,000   \n",
       "45                                  youtubedude      2,300,000   \n",
       "46                                   Nikesoccer        255,000   \n",
       "47                                       larfus        247,000   \n",
       "48                                        jawed              1   \n",
       "\n",
       "          Upload_date              Views  \n",
       "30   November 2, 2020      June 17, 2016  \n",
       "31     August 4, 2017   January 12, 2017  \n",
       "32      July 10, 2017      April 6, 2015  \n",
       "33  November 24, 2012      July 15, 2012  \n",
       "34      July 16, 2010  February 19, 2010  \n",
       "35     April 14, 2010  November 24, 2009  \n",
       "36   October 25, 2009       May 22, 2007  \n",
       "37        May 2, 2009      April 6, 2006  \n",
       "38      July 17, 2008  February 27, 2007  \n",
       "39     March 15, 2008      April 6, 2006  \n",
       "40      March 1, 2008      April 9, 2007  \n",
       "41       May 19, 2006      April 6, 2006  \n",
       "42     March 12, 2006  November 28, 2005  \n",
       "43  February 18, 2006   January 31, 2006  \n",
       "44   January 21, 2006   December 1, 2005  \n",
       "45    January 9, 2006  December 18, 2005  \n",
       "46   October 31, 2005   October 21, 2005  \n",
       "47   October 29, 2005    October 5, 2005  \n",
       "48     April 23, 2005     April 23, 2005  "
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "print(\" ****** Progression of the most-viewed video on YouTube *****\")\n",
    "\n",
    "video_details_df.iloc[30:49,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae90a71",
   "metadata": {},
   "source": [
    "**2.** Scrape the details team India’s international fixtures from bcci.tv.\n",
    "Url = https://www.bcci.tv/.\n",
    "You need to find following details:\n",
    "A) Match title (I.e. 1\n",
    "st ODI)\n",
    "B) Series\n",
    "C) Place\n",
    "D) Date\n",
    "E) Time\n",
    "Note: - From bcci.tv home page you have reach to the international fixture page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "498345e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first connect to the webdriver\n",
    "driver= webdriver.Chrome(r\"C:\\Users\\nbson\\Downloads\\chromedriver_win32 (3)\\chromedriver.exe\")\n",
    "#connection after uploading driver in jupyter notebook\n",
    "driver=webdriver.Chrome(\"chromedriver.exe\")\n",
    "url = \" https://www.bcci.tv/\"\n",
    "driver.get(url)\n",
    "\n",
    "time.sleep(2)\n",
    "\n",
    "int_tab =driver.find_element_by_xpath('//li[@class=\"nav-item ml-0\"]').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "882e54c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Match_Title</th>\n",
       "      <th>Series</th>\n",
       "      <th>Place</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1st T20I -</td>\n",
       "      <td>SOUTH AFRICA TOUR OF INDIA T20 SERIES 2022</td>\n",
       "      <td>1st T20I - Arun Jaitley Stadium, Delhi</td>\n",
       "      <td>9 JUN 2022</td>\n",
       "      <td>7:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2nd T20I -</td>\n",
       "      <td>SOUTH AFRICA TOUR OF INDIA T20 SERIES 2022</td>\n",
       "      <td>2nd T20I - Barabati Stadium, Cuttack</td>\n",
       "      <td>12 JUN 2022</td>\n",
       "      <td>7:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3rd T20I -</td>\n",
       "      <td>SOUTH AFRICA TOUR OF INDIA T20 SERIES 2022</td>\n",
       "      <td>3rd T20I - Dr YS Rajasekhara Reddy ACA-VDCA Cr...</td>\n",
       "      <td>14 JUN 2022</td>\n",
       "      <td>7:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4th T20I -</td>\n",
       "      <td>SOUTH AFRICA TOUR OF INDIA T20 SERIES 2022</td>\n",
       "      <td>4th T20I - Saurashtra Cricket Association Stad...</td>\n",
       "      <td>17 JUN 2022</td>\n",
       "      <td>7:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5th T20I -</td>\n",
       "      <td>SOUTH AFRICA TOUR OF INDIA T20 SERIES 2022</td>\n",
       "      <td>5th T20I - M Chinnaswamy Stadium, Bengaluru</td>\n",
       "      <td>19 JUN 2022</td>\n",
       "      <td>7:30 PM IST</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Match_Title                                      Series  \\\n",
       "0  1st T20I -  SOUTH AFRICA TOUR OF INDIA T20 SERIES 2022   \n",
       "1  2nd T20I -  SOUTH AFRICA TOUR OF INDIA T20 SERIES 2022   \n",
       "2  3rd T20I -  SOUTH AFRICA TOUR OF INDIA T20 SERIES 2022   \n",
       "3  4th T20I -  SOUTH AFRICA TOUR OF INDIA T20 SERIES 2022   \n",
       "4  5th T20I -  SOUTH AFRICA TOUR OF INDIA T20 SERIES 2022   \n",
       "\n",
       "                                               Place         Date         Time  \n",
       "0             1st T20I - Arun Jaitley Stadium, Delhi   9 JUN 2022  7:30 PM IST  \n",
       "1               2nd T20I - Barabati Stadium, Cuttack  12 JUN 2022  7:30 PM IST  \n",
       "2  3rd T20I - Dr YS Rajasekhara Reddy ACA-VDCA Cr...  14 JUN 2022  7:30 PM IST  \n",
       "3  4th T20I - Saurashtra Cricket Association Stad...  17 JUN 2022  7:30 PM IST  \n",
       "4        5th T20I - M Chinnaswamy Stadium, Bengaluru  19 JUN 2022  7:30 PM IST  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating empty lists\n",
    "Match_Title=[]\n",
    "Series =[]\n",
    "Place=[]\n",
    "Date = []\n",
    "Time=[]\n",
    "\n",
    "# extracting title\n",
    "titles=driver.find_elements_by_xpath('//span[@class=\"matchOrderText ng-binding ng-scope\"]')\n",
    "\n",
    "# extracting series\n",
    "series =driver.find_elements_by_xpath('//span[@class=\"ng-binding\"]')\n",
    "\n",
    "#extarcting places\n",
    "places=driver.find_elements_by_xpath('//div[@class=\"fix-place ng-binding ng-scope\"]')\n",
    "\n",
    "# extracting date \n",
    "dates=driver.find_elements_by_xpath('//div[@class=\"match-card-left match-schedule\"]')\n",
    "\n",
    "# extracting time\n",
    "times=driver.find_elements_by_xpath('//div[@class=\"match-card-right match-schedule \"]')\n",
    "\n",
    "for i in range(len(titles)):\n",
    "    title=titles[i].text     \n",
    "    Match_Title.append(title)\n",
    "    \n",
    "    place=places[i].text     \n",
    "    Place.append(place)\n",
    "    \n",
    "    serie=series[i].text     \n",
    "    Series.append(serie)\n",
    "    \n",
    "    time=times[i].text     \n",
    "    Time.append(time)\n",
    "    \n",
    "    date=dates[i].text     \n",
    "    Date.append(date)\n",
    "\n",
    "\n",
    "\n",
    "# Make dataframe\n",
    "India_details_df = pd.DataFrame({'Match_Title':Match_Title,'Series':Series,'Place':Place,'Date':Date,'Time':Time})\n",
    "India_details_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ad0010",
   "metadata": {},
   "source": [
    "**3.** Scrape the details of selenium exception from guru99.com.\n",
    "Url = https://www.guru99.com/\n",
    "You need to find following details:\n",
    "A) Name\n",
    "B) Description\n",
    "Note: - From guru99 home page you have to reach to selenium exception handling page through cod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "d894a500",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "# first connect to the webdriver\n",
    "driver= webdriver.Chrome(r\"C:\\Users\\nbson\\Downloads\\chromedriver_win32 (3)\\chromedriver.exe\")\n",
    "#connection after uploading driver in jupyter notebook\n",
    "driver=webdriver.Chrome(\"chromedriver.exe\")\n",
    "url = \"https://www.guru99.com/ \"\n",
    "driver.get(url)\n",
    "\n",
    "time.sleep(2)\n",
    "\n",
    "driver.find_element_by_xpath('//*[@id=\"menu-item-3173\"]/a/span/span').click()\n",
    "driver.find_element_by_xpath('//*[@id=\"menu-item-4622\"]').click()\n",
    "\n",
    "driver.find_element_by_xpath('//*[@id=\"post-193\"]/div/div/table[5]/tbody/tr[34]/td[1]/a').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "428afec8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Exception_name</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ElementNotVisibleException</td>\n",
       "      <td>This type of Selenium exception occurs when an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ElementNotSelectableException</td>\n",
       "      <td>This Selenium exception occurs when an element...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NoSuchElementException</td>\n",
       "      <td>This Exception occurs if an element could not ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NoSuchFrameException</td>\n",
       "      <td>This Exception occurs if the frame target to b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NoAlertPresentException</td>\n",
       "      <td>This Exception occurs when you switch to no pr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Exception_name  \\\n",
       "0     ElementNotVisibleException   \n",
       "1  ElementNotSelectableException   \n",
       "2         NoSuchElementException   \n",
       "3           NoSuchFrameException   \n",
       "4        NoAlertPresentException   \n",
       "\n",
       "                                         Description  \n",
       "0  This type of Selenium exception occurs when an...  \n",
       "1  This Selenium exception occurs when an element...  \n",
       "2  This Exception occurs if an element could not ...  \n",
       "3  This Exception occurs if the frame target to b...  \n",
       "4  This Exception occurs when you switch to no pr...  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#extracting content\n",
    "rows= driver.find_elements_by_xpath('//table[@class=\"table table-striped\"]/tbody/tr')\n",
    "len(rows)\n",
    "i=1\n",
    "Exception_name=[]\n",
    "Description=[]\n",
    "for row in rows[1:] :\n",
    "    tds=row.find_elements_by_tag_name('td')\n",
    "    Exception_name.append(tds[0].text)\n",
    "    Description.append(tds[1].text)\n",
    "Exception_details=pd.DataFrame({'Exception_name': Exception_name ,'Description':Description})    \n",
    "Exception_details.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68765670",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b18f993c",
   "metadata": {},
   "source": [
    "**4.** Scrape the details of State-wise GDP of India from statisticstime.com.\n",
    "Url = http://statisticstimes.com/\n",
    "You have to find following details:\n",
    "A) Rank\n",
    "B) State\n",
    "C) GSDP(18-19)\n",
    "D) GSDP(17-18)\n",
    "E) Share(2017)\n",
    "F) GDP($ billion)\n",
    "Note: - From statisticstimes home page you have to reach to economy page through code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bd051730",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NoSuchElementException",
     "evalue": "Message: no such element: Unable to locate element: {\"method\":\"xpath\",\"selector\":\"/html/body/div[1]/div[2]/div[2]/div/div/div/div/div[1]\"}\n  (Session info: chrome=100.0.4896.127)\nStacktrace:\nBacktrace:\n\tOrdinal0 [0x00309943+2595139]\n\tOrdinal0 [0x0029C9F1+2148849]\n\tOrdinal0 [0x00194528+1066280]\n\tOrdinal0 [0x001C0FD4+1249236]\n\tOrdinal0 [0x001C11CB+1249739]\n\tOrdinal0 [0x001ED812+1431570]\n\tOrdinal0 [0x001DBA34+1358388]\n\tOrdinal0 [0x001EBAF2+1424114]\n\tOrdinal0 [0x001DB806+1357830]\n\tOrdinal0 [0x001B6086+1204358]\n\tOrdinal0 [0x001B6F96+1208214]\n\tGetHandleVerifier [0x004AB232+1658114]\n\tGetHandleVerifier [0x0056312C+2411516]\n\tGetHandleVerifier [0x0039F261+560433]\n\tGetHandleVerifier [0x0039E366+556598]\n\tOrdinal0 [0x002A286B+2173035]\n\tOrdinal0 [0x002A75F8+2192888]\n\tOrdinal0 [0x002A76E5+2193125]\n\tOrdinal0 [0x002B11FC+2232828]\n\tBaseThreadInitThunk [0x7726FA29+25]\n\tRtlGetAppContainerNamedObjectPath [0x77E97A7E+286]\n\tRtlGetAppContainerNamedObjectPath [0x77E97A4E+238]\n\t(No symbol) [0x00000000]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNoSuchElementException\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-fe610f76d701>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;31m# time.sleep(1)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_element_by_xpath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/html/body/div[1]/div[2]/div[2]/div/div/div/div/div[1]'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclick\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m \u001b[1;31m#driver.find_element_by_id('dismiss-button').click(); #Close Ad\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mswitchTo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdefaultContent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m      \u001b[1;31m# Return to main window\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mfind_element_by_xpath\u001b[1;34m(self, xpath)\u001b[0m\n\u001b[0;32m    519\u001b[0m             \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    520\u001b[0m         )\n\u001b[1;32m--> 521\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_element\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mby\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mXPATH\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mxpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    522\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    523\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfind_elements_by_xpath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxpath\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mList\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mWebElement\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mfind_element\u001b[1;34m(self, by, value)\u001b[0m\n\u001b[0;32m   1246\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'[name=\"%s\"]'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1247\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1248\u001b[1;33m         return self.execute(Command.FIND_ELEMENT, {\n\u001b[0m\u001b[0;32m   1249\u001b[0m             \u001b[1;34m'using'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mby\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1250\u001b[0m             'value': value})['value']\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    423\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    424\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 425\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    426\u001b[0m             response['value'] = self._unwrap_value(\n\u001b[0;32m    427\u001b[0m                 response.get('value', None))\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py\u001b[0m in \u001b[0;36mcheck_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    245\u001b[0m                 \u001b[0malert_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'alert'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    246\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malert_text\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 247\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    248\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    249\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_value_or_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mMapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0m_KT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_VT\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0m_KT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0m_VT\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0m_VT\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNoSuchElementException\u001b[0m: Message: no such element: Unable to locate element: {\"method\":\"xpath\",\"selector\":\"/html/body/div[1]/div[2]/div[2]/div/div/div/div/div[1]\"}\n  (Session info: chrome=100.0.4896.127)\nStacktrace:\nBacktrace:\n\tOrdinal0 [0x00309943+2595139]\n\tOrdinal0 [0x0029C9F1+2148849]\n\tOrdinal0 [0x00194528+1066280]\n\tOrdinal0 [0x001C0FD4+1249236]\n\tOrdinal0 [0x001C11CB+1249739]\n\tOrdinal0 [0x001ED812+1431570]\n\tOrdinal0 [0x001DBA34+1358388]\n\tOrdinal0 [0x001EBAF2+1424114]\n\tOrdinal0 [0x001DB806+1357830]\n\tOrdinal0 [0x001B6086+1204358]\n\tOrdinal0 [0x001B6F96+1208214]\n\tGetHandleVerifier [0x004AB232+1658114]\n\tGetHandleVerifier [0x0056312C+2411516]\n\tGetHandleVerifier [0x0039F261+560433]\n\tGetHandleVerifier [0x0039E366+556598]\n\tOrdinal0 [0x002A286B+2173035]\n\tOrdinal0 [0x002A75F8+2192888]\n\tOrdinal0 [0x002A76E5+2193125]\n\tOrdinal0 [0x002B11FC+2232828]\n\tBaseThreadInitThunk [0x7726FA29+25]\n\tRtlGetAppContainerNamedObjectPath [0x77E97A7E+286]\n\tRtlGetAppContainerNamedObjectPath [0x77E97A4E+238]\n\t(No symbol) [0x00000000]\n"
     ]
    }
   ],
   "source": [
    "# first connect to the webdriver\n",
    "driver= webdriver.Chrome(r\"C:\\Users\\nbson\\Downloads\\chromedriver_win32 (3)\\chromedriver.exe\")\n",
    "#connection after uploading driver in jupyter notebook\n",
    "driver=webdriver.Chrome(\"chromedriver.exe\")\n",
    "url = \"http://statisticstimes.com/ \"\n",
    "driver.get(url)\n",
    "\n",
    "time.sleep(2)\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "\n",
    "\n",
    "#object of ActionChains\n",
    "a = ActionChains(driver)\n",
    "#identify element\n",
    "m = driver.find_element_by_xpath('//*[@id=\"top\"]/div[2]/div[2]/button')\n",
    "#hover over element\n",
    "a.move_to_element(m).perform()\n",
    "#identify sub menu element\n",
    "n = driver.find_element_by_xpath('//*[@id=\"top\"]/div[2]/div[2]/div/a[3]')\n",
    "# hover over element and click\n",
    "time.sleep(1)\n",
    "a.move_to_element(n).click().perform()\n",
    "\n",
    "driver.find_element_by_xpath('/html/body/div[1]/div[2]/div[2]/div/div/div/div/div[1]').click()\n",
    "\n",
    "driver.switchTo().defaultContent();      # Return to main window\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cfad92fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>State</th>\n",
       "      <th>GSDP_19_20</th>\n",
       "      <th>GSDP_18_19</th>\n",
       "      <th>Share_2018</th>\n",
       "      <th>GDP_billion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>-</td>\n",
       "      <td>2,632,792</td>\n",
       "      <td>13.94%</td>\n",
       "      <td>399.921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Tamil Nadu</td>\n",
       "      <td>1,845,853</td>\n",
       "      <td>1,630,208</td>\n",
       "      <td>8.63%</td>\n",
       "      <td>247.629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>1,687,818</td>\n",
       "      <td>1,584,764</td>\n",
       "      <td>8.39%</td>\n",
       "      <td>240.726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Gujarat</td>\n",
       "      <td>-</td>\n",
       "      <td>1,502,899</td>\n",
       "      <td>7.96%</td>\n",
       "      <td>228.290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>1,631,977</td>\n",
       "      <td>1,493,127</td>\n",
       "      <td>7.91%</td>\n",
       "      <td>226.806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>West Bengal</td>\n",
       "      <td>1,253,832</td>\n",
       "      <td>1,089,898</td>\n",
       "      <td>5.77%</td>\n",
       "      <td>165.556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Rajasthan</td>\n",
       "      <td>1,020,989</td>\n",
       "      <td>942,586</td>\n",
       "      <td>4.99%</td>\n",
       "      <td>143.179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>972,782</td>\n",
       "      <td>862,957</td>\n",
       "      <td>4.57%</td>\n",
       "      <td>131.083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Telangana</td>\n",
       "      <td>969,604</td>\n",
       "      <td>861,031</td>\n",
       "      <td>4.56%</td>\n",
       "      <td>130.791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Madhya Pradesh</td>\n",
       "      <td>906,672</td>\n",
       "      <td>809,592</td>\n",
       "      <td>4.29%</td>\n",
       "      <td>122.977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>Kerala</td>\n",
       "      <td>-</td>\n",
       "      <td>781,653</td>\n",
       "      <td>4.14%</td>\n",
       "      <td>118.733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>856,112</td>\n",
       "      <td>774,870</td>\n",
       "      <td>4.10%</td>\n",
       "      <td>117.703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>Haryana</td>\n",
       "      <td>831,610</td>\n",
       "      <td>734,163</td>\n",
       "      <td>3.89%</td>\n",
       "      <td>111.519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>Bihar</td>\n",
       "      <td>611,804</td>\n",
       "      <td>530,363</td>\n",
       "      <td>2.81%</td>\n",
       "      <td>80.562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>Punjab</td>\n",
       "      <td>574,760</td>\n",
       "      <td>526,376</td>\n",
       "      <td>2.79%</td>\n",
       "      <td>79.957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>Odisha</td>\n",
       "      <td>521,275</td>\n",
       "      <td>487,805</td>\n",
       "      <td>2.58%</td>\n",
       "      <td>74.098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>Assam</td>\n",
       "      <td>-</td>\n",
       "      <td>315,881</td>\n",
       "      <td>1.67%</td>\n",
       "      <td>47.982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>Chhattisgarh</td>\n",
       "      <td>329,180</td>\n",
       "      <td>304,063</td>\n",
       "      <td>1.61%</td>\n",
       "      <td>46.187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>Jharkhand</td>\n",
       "      <td>328,598</td>\n",
       "      <td>297,204</td>\n",
       "      <td>1.57%</td>\n",
       "      <td>45.145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>Uttarakhand</td>\n",
       "      <td>-</td>\n",
       "      <td>245,895</td>\n",
       "      <td>1.30%</td>\n",
       "      <td>37.351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>Jammu &amp; Kashmir</td>\n",
       "      <td>-</td>\n",
       "      <td>155,956</td>\n",
       "      <td>0.83%</td>\n",
       "      <td>23.690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>Himachal Pradesh</td>\n",
       "      <td>165,472</td>\n",
       "      <td>153,845</td>\n",
       "      <td>0.81%</td>\n",
       "      <td>23.369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>Goa</td>\n",
       "      <td>80,449</td>\n",
       "      <td>73,170</td>\n",
       "      <td>0.39%</td>\n",
       "      <td>11.115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>Tripura</td>\n",
       "      <td>55,984</td>\n",
       "      <td>49,845</td>\n",
       "      <td>0.26%</td>\n",
       "      <td>7.571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>Chandigarh</td>\n",
       "      <td>-</td>\n",
       "      <td>42,114</td>\n",
       "      <td>0.22%</td>\n",
       "      <td>6.397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>Puducherry</td>\n",
       "      <td>38,253</td>\n",
       "      <td>34,433</td>\n",
       "      <td>0.18%</td>\n",
       "      <td>5.230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>Meghalaya</td>\n",
       "      <td>36,572</td>\n",
       "      <td>33,481</td>\n",
       "      <td>0.18%</td>\n",
       "      <td>5.086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>Sikkim</td>\n",
       "      <td>32,496</td>\n",
       "      <td>28,723</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>4.363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>Manipur</td>\n",
       "      <td>31,790</td>\n",
       "      <td>27,870</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>4.233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>Nagaland</td>\n",
       "      <td>-</td>\n",
       "      <td>27,283</td>\n",
       "      <td>0.14%</td>\n",
       "      <td>4.144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31</td>\n",
       "      <td>Arunachal Pradesh</td>\n",
       "      <td>-</td>\n",
       "      <td>24,603</td>\n",
       "      <td>0.13%</td>\n",
       "      <td>3.737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32</td>\n",
       "      <td>Mizoram</td>\n",
       "      <td>26,503</td>\n",
       "      <td>22,287</td>\n",
       "      <td>0.12%</td>\n",
       "      <td>3.385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>33</td>\n",
       "      <td>Andaman &amp; Nicobar Islands</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                      State GSDP_19_20 GSDP_18_19 Share_2018  \\\n",
       "0     1                Maharashtra          -  2,632,792     13.94%   \n",
       "1     2                 Tamil Nadu  1,845,853  1,630,208      8.63%   \n",
       "2     3              Uttar Pradesh  1,687,818  1,584,764      8.39%   \n",
       "3     4                    Gujarat          -  1,502,899      7.96%   \n",
       "4     5                  Karnataka  1,631,977  1,493,127      7.91%   \n",
       "5     6                West Bengal  1,253,832  1,089,898      5.77%   \n",
       "6     7                  Rajasthan  1,020,989    942,586      4.99%   \n",
       "7     8             Andhra Pradesh    972,782    862,957      4.57%   \n",
       "8     9                  Telangana    969,604    861,031      4.56%   \n",
       "9    10             Madhya Pradesh    906,672    809,592      4.29%   \n",
       "10   11                     Kerala          -    781,653      4.14%   \n",
       "11   12                      Delhi    856,112    774,870      4.10%   \n",
       "12   13                    Haryana    831,610    734,163      3.89%   \n",
       "13   14                      Bihar    611,804    530,363      2.81%   \n",
       "14   15                     Punjab    574,760    526,376      2.79%   \n",
       "15   16                     Odisha    521,275    487,805      2.58%   \n",
       "16   17                      Assam          -    315,881      1.67%   \n",
       "17   18               Chhattisgarh    329,180    304,063      1.61%   \n",
       "18   19                  Jharkhand    328,598    297,204      1.57%   \n",
       "19   20                Uttarakhand          -    245,895      1.30%   \n",
       "20   21            Jammu & Kashmir          -    155,956      0.83%   \n",
       "21   22           Himachal Pradesh    165,472    153,845      0.81%   \n",
       "22   23                        Goa     80,449     73,170      0.39%   \n",
       "23   24                    Tripura     55,984     49,845      0.26%   \n",
       "24   25                 Chandigarh          -     42,114      0.22%   \n",
       "25   26                 Puducherry     38,253     34,433      0.18%   \n",
       "26   27                  Meghalaya     36,572     33,481      0.18%   \n",
       "27   28                     Sikkim     32,496     28,723      0.15%   \n",
       "28   29                    Manipur     31,790     27,870      0.15%   \n",
       "29   30                   Nagaland          -     27,283      0.14%   \n",
       "30   31          Arunachal Pradesh          -     24,603      0.13%   \n",
       "31   32                    Mizoram     26,503     22,287      0.12%   \n",
       "32   33  Andaman & Nicobar Islands          -          -          -   \n",
       "\n",
       "   GDP_billion  \n",
       "0      399.921  \n",
       "1      247.629  \n",
       "2      240.726  \n",
       "3      228.290  \n",
       "4      226.806  \n",
       "5      165.556  \n",
       "6      143.179  \n",
       "7      131.083  \n",
       "8      130.791  \n",
       "9      122.977  \n",
       "10     118.733  \n",
       "11     117.703  \n",
       "12     111.519  \n",
       "13      80.562  \n",
       "14      79.957  \n",
       "15      74.098  \n",
       "16      47.982  \n",
       "17      46.187  \n",
       "18      45.145  \n",
       "19      37.351  \n",
       "20      23.690  \n",
       "21      23.369  \n",
       "22      11.115  \n",
       "23       7.571  \n",
       "24       6.397  \n",
       "25       5.230  \n",
       "26       5.086  \n",
       "27       4.363  \n",
       "28       4.233  \n",
       "29       4.144  \n",
       "30       3.737  \n",
       "31       3.385  \n",
       "32           -  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows=driver.find_elements_by_xpath('//table[@id=\"table_id\"]/tbody/tr')\n",
    "#making empty lists\n",
    "Rank=[] \n",
    "State=[] \n",
    "GSDP_18_19=[] \n",
    "GSDP_19_20=[]\n",
    "Share_2018=[]\n",
    "GDP_billion =[]\n",
    "\n",
    "for i in rows:\n",
    "    # scraping all columns in row\n",
    "    cols=i.find_elements_by_tag_name('td')\n",
    "    Rank.append(cols[0].text) \n",
    "    State.append(cols[1].text) \n",
    "    GSDP_19_20.append(cols[2].text) \n",
    "    GSDP_18_19.append(cols[3].text) \n",
    "    Share_2018.append(cols[4].text) \n",
    "    GDP_billion.append(cols[5].text) \n",
    "\n",
    "#making Dataframe\n",
    "GDP=pd.DataFrame({'Rank':Rank,'State':State ,'GSDP_19_20':GSDP_19_20 ,'GSDP_18_19':GSDP_18_19,\n",
    "                  'Share_2018':Share_2018 ,'GDP_billion':GDP_billion})\n",
    "GDP                          "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f3405b",
   "metadata": {},
   "source": [
    "**5.** Scrape the details of trending repositories on Github.com.\n",
    "Url = https://github.com/\n",
    "You have to find the following details:\n",
    "A) Repository title\n",
    "B) Repository description\n",
    "C) Contributors count\n",
    "D) Language used\n",
    "ASSIGNMENT\n",
    "Note: - From the home page you have to click on the trending option from Explore menu through cod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "90cac440",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Titles</th>\n",
       "      <th>Descriptions</th>\n",
       "      <th>Languages</th>\n",
       "      <th>Contributers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PowerShell / PowerShell</td>\n",
       "      <td>PowerShell for every system!</td>\n",
       "      <td>C#</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ruanyf / weekly</td>\n",
       "      <td>科技爱好者周刊，每周五发布</td>\n",
       "      <td>TypeScript</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>angular / angular</td>\n",
       "      <td>The modern web developer’s platform</td>\n",
       "      <td>Ruby</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mastodon / mastodon</td>\n",
       "      <td>Your self-hosted, globally interconnected micr...</td>\n",
       "      <td>TypeScript</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>spacedriveapp / spacedrive</td>\n",
       "      <td>Spacedrive is an open source cross-platform fi...</td>\n",
       "      <td>Python</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ml-tooling / best-of-ml-python</td>\n",
       "      <td>🏆 A ranked list of awesome machine learning Py...</td>\n",
       "      <td>-</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>jsonhero-io / jsonhero-web</td>\n",
       "      <td>JSON Hero is an open-source, beautiful JSON ex...</td>\n",
       "      <td>TypeScript</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>gradio-app / gradio</td>\n",
       "      <td>Create UIs for your machine learning model in ...</td>\n",
       "      <td>Python</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>appsmithorg / appsmith</td>\n",
       "      <td>Low code project to build admin panels, intern...</td>\n",
       "      <td>TypeScript</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>google / wireit</td>\n",
       "      <td>Wireit upgrades your npm scripts to make them ...</td>\n",
       "      <td>TypeScript</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>naver / fe-news</td>\n",
       "      <td>FE 기술 소식 큐레이션 뉴스레터</td>\n",
       "      <td>Java</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Trainguy9512 / trainguys-animation-overhaul</td>\n",
       "      <td>润学全球官方指定GITHUB，整理润学宗旨、纲领、理论和各类润之实例；解决为什么润，润去哪里...</td>\n",
       "      <td>-</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>The-Run-Philosophy-Organization / run</td>\n",
       "      <td>A multi-voice TTS system trained with an empha...</td>\n",
       "      <td>Python</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>neonbjb / tortoise-tts</td>\n",
       "      <td>-</td>\n",
       "      <td>C</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>F5OEO / rpitx</td>\n",
       "      <td>RF transmitter for Raspberry Pi</td>\n",
       "      <td>-</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>hlorus / CAD_Sketcher</td>\n",
       "      <td>Constraint-based geometry sketcher for blender</td>\n",
       "      <td>-</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>why20021008 / hand-write</td>\n",
       "      <td>模拟手写效果，节约时间。</td>\n",
       "      <td>Python</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>rejetto / hfs</td>\n",
       "      <td>HFS is a file server offering a virtual file s...</td>\n",
       "      <td>Python</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>rancher / rancher</td>\n",
       "      <td>Complete container management platform</td>\n",
       "      <td>TypeScript</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>jwasham / coding-interview-university</td>\n",
       "      <td>A complete computer science study plan to beco...</td>\n",
       "      <td>Go</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>ruilisi / fortune-sheet</td>\n",
       "      <td>A drop-in javascript spreadsheet library that ...</td>\n",
       "      <td>TypeScript</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>RedisInsight / RedisInsight</td>\n",
       "      <td>RedisInsight</td>\n",
       "      <td>TypeScript</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>terraform-aws-modules / terraform-aws-eks</td>\n",
       "      <td>Terraform module to create an Elastic Kubernet...</td>\n",
       "      <td>HCL</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>FrancescoXX / free-Web3-resources</td>\n",
       "      <td>A list of FREE resources to make Web3 accessib...</td>\n",
       "      <td>HTML</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Dec0ne / KrbRelayUp</td>\n",
       "      <td>KrbRelayUp - a universal no-fix local privileg...</td>\n",
       "      <td>C#</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Titles  \\\n",
       "0                       PowerShell / PowerShell   \n",
       "1                               ruanyf / weekly   \n",
       "2                             angular / angular   \n",
       "3                           mastodon / mastodon   \n",
       "4                    spacedriveapp / spacedrive   \n",
       "5                ml-tooling / best-of-ml-python   \n",
       "6                    jsonhero-io / jsonhero-web   \n",
       "7                           gradio-app / gradio   \n",
       "8                        appsmithorg / appsmith   \n",
       "9                               google / wireit   \n",
       "10                              naver / fe-news   \n",
       "11  Trainguy9512 / trainguys-animation-overhaul   \n",
       "12        The-Run-Philosophy-Organization / run   \n",
       "13                       neonbjb / tortoise-tts   \n",
       "14                                F5OEO / rpitx   \n",
       "15                        hlorus / CAD_Sketcher   \n",
       "16                     why20021008 / hand-write   \n",
       "17                                rejetto / hfs   \n",
       "18                            rancher / rancher   \n",
       "19        jwasham / coding-interview-university   \n",
       "20                      ruilisi / fortune-sheet   \n",
       "21                  RedisInsight / RedisInsight   \n",
       "22    terraform-aws-modules / terraform-aws-eks   \n",
       "23            FrancescoXX / free-Web3-resources   \n",
       "24                          Dec0ne / KrbRelayUp   \n",
       "\n",
       "                                         Descriptions   Languages  \\\n",
       "0                        PowerShell for every system!          C#   \n",
       "1                                       科技爱好者周刊，每周五发布  TypeScript   \n",
       "2                 The modern web developer’s platform        Ruby   \n",
       "3   Your self-hosted, globally interconnected micr...  TypeScript   \n",
       "4   Spacedrive is an open source cross-platform fi...      Python   \n",
       "5   🏆 A ranked list of awesome machine learning Py...          -    \n",
       "6   JSON Hero is an open-source, beautiful JSON ex...  TypeScript   \n",
       "7   Create UIs for your machine learning model in ...      Python   \n",
       "8   Low code project to build admin panels, intern...  TypeScript   \n",
       "9   Wireit upgrades your npm scripts to make them ...  TypeScript   \n",
       "10                                 FE 기술 소식 큐레이션 뉴스레터        Java   \n",
       "11  润学全球官方指定GITHUB，整理润学宗旨、纲领、理论和各类润之实例；解决为什么润，润去哪里...          -    \n",
       "12  A multi-voice TTS system trained with an empha...      Python   \n",
       "13                                                 -            C   \n",
       "14                    RF transmitter for Raspberry Pi          -    \n",
       "15     Constraint-based geometry sketcher for blender          -    \n",
       "16                                       模拟手写效果，节约时间。      Python   \n",
       "17  HFS is a file server offering a virtual file s...      Python   \n",
       "18             Complete container management platform  TypeScript   \n",
       "19  A complete computer science study plan to beco...          Go   \n",
       "20  A drop-in javascript spreadsheet library that ...  TypeScript   \n",
       "21                                       RedisInsight  TypeScript   \n",
       "22  Terraform module to create an Elastic Kubernet...         HCL   \n",
       "23  A list of FREE resources to make Web3 accessib...        HTML   \n",
       "24  KrbRelayUp - a universal no-fix local privileg...          C#   \n",
       "\n",
       "    Contributers  \n",
       "0              5  \n",
       "1              5  \n",
       "2              5  \n",
       "3              5  \n",
       "4              5  \n",
       "5              5  \n",
       "6              5  \n",
       "7              5  \n",
       "8              5  \n",
       "9              4  \n",
       "10             5  \n",
       "11             4  \n",
       "12             5  \n",
       "13             2  \n",
       "14             5  \n",
       "15             4  \n",
       "16             1  \n",
       "17             1  \n",
       "18             5  \n",
       "19             5  \n",
       "20             5  \n",
       "21             5  \n",
       "22             5  \n",
       "23             5  \n",
       "24             2  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver= webdriver.Chrome(r\"C:\\Users\\nbson\\Downloads\\chromedriver_win32 (3)\\chromedriver.exe\")\n",
    "#connection after uploading driver in jupyter notebook\n",
    "driver=webdriver.Chrome(\"chromedriver.exe\")\n",
    "url = \"https://github.com/ \"\n",
    "driver.get(url)\n",
    "\n",
    "time.sleep(2)\n",
    "\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "\n",
    "\n",
    "#object of ActionChains\n",
    "a = ActionChains(driver)\n",
    "#identify element\n",
    "m = driver.find_element_by_xpath('/html/body/div[1]/header/div/div[2]/nav/ul/li[4]/details/summary')\n",
    "#hover over element\n",
    "a.move_to_element(m).perform()\n",
    "time.sleep(1)\n",
    "#identify sub menu element\n",
    "n = driver.find_element_by_xpath('/html/body/div[1]/header/div/div[2]/nav/ul/li[4]/details/div/ul/li[5]/a')\n",
    "# hover over element and click\n",
    "time.sleep(1)\n",
    "a.move_to_element(n).click().perform()\n",
    "\n",
    "Titles=[]\n",
    "Descriptions=[]\n",
    "Languages=[]\n",
    "Contributers=[]\n",
    "\n",
    "titles=driver.find_elements_by_xpath('//h1[@class=\"h3 lh-condensed\"]/a')\n",
    "descriptions=driver.find_elements_by_xpath('//p[@class=\"col-9 color-fg-muted my-1 pr-4\"]')\n",
    "languages=driver.find_elements_by_xpath('//span[@itemprop=\"programmingLanguage\"]')\n",
    "contributers=driver.find_elements_by_xpath('//span[@class=\"d-inline-block mr-3\"]')\n",
    "\n",
    "#scraping titles\n",
    "for i in range(len(titles)):\n",
    "    Titles.append(titles[i].text)\n",
    "  \n",
    "#scraping Descriptions\n",
    "for i in range(len(descriptions)): \n",
    "    Descriptions.append(descriptions[i].text)\n",
    "\n",
    "#scraping Languages\n",
    "for i in range(len(languages)): \n",
    "    Languages.append(languages[i].text)\n",
    "    \n",
    "#scraping contributors\n",
    "contributers=driver.find_elements_by_xpath('//span[@class=\"d-inline-block mr-3\"]')\n",
    "for i in contributers:\n",
    "    contri_total=i.find_elements_by_css_selector('a')\n",
    "    Contributers.append(len(contri_total))\n",
    "\n",
    "    \n",
    "# inserting '-' at index 13 since no record found\n",
    "Descriptions.insert(13,' - ')\n",
    "\n",
    "# inserting '-' at index [5,11,14,15] since no record found\n",
    "index=[5,11,14,15]\n",
    "for i in index :\n",
    "    Languages.insert(i,' - ')\n",
    "\n",
    "github_trending=pd.DataFrame({'Titles':Titles,'Descriptions':Descriptions ,'Languages':Languages ,'Contributers':Contributers})\n",
    "github_trending"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c180405c",
   "metadata": {},
   "source": [
    "**6.** Scrape the details of top 100 songs on billiboard.com.\n",
    "Url = https:/www.billboard.com/\n",
    "You have to find the following details:\n",
    "A) Song name\n",
    "B) Artist name\n",
    "C) Last week rank\n",
    "D) Peak rank\n",
    "E) Weeks on board\n",
    "Note: - From the home page you have to click on the charts option then hot 100-page link through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf3117b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver= webdriver.Chrome(r\"C:\\Users\\nbson\\Downloads\\chromedriver_win32 (3)\\chromedriver.exe\")\n",
    "#connection after uploading driver in jupyter notebook\n",
    "driver=webdriver.Chrome(\"chromedriver.exe\")\n",
    "url = \"https:/www.billboard.com/\"\n",
    "driver.get(url)\n",
    "driver.maximize_window()\n",
    "time.sleep(2)\n",
    "driver.find_element_by_xpath('//*[@id=\"main-wrapper\"]/header/div[2]/div/nav/ul/li[1]/a').click()\n",
    "Song_name=[]  \n",
    "Artist_name=[] \n",
    "Last_week_rank=[] \n",
    "Peak_rank=[]  \n",
    "Weeks_on_board=[]\n",
    "\n",
    "# closing floating personal ad\n",
    "driver.find_element_by_xpath('/html/body/div[2]/div/span').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d4c24a1d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Song_name</th>\n",
       "      <th>Artist_name</th>\n",
       "      <th>Last_week_rank</th>\n",
       "      <th>Peak_rank</th>\n",
       "      <th>Weeks_on_board</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>As It Was</td>\n",
       "      <td>Harry Styles</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>First Class</td>\n",
       "      <td>Jack Harlow</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Heat Waves</td>\n",
       "      <td>Glass Animals</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Big Energy</td>\n",
       "      <td>Latto</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Enemy</td>\n",
       "      <td>Imagine Dragons X JID</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>P Power</td>\n",
       "      <td>Gunna Featuring Drake</td>\n",
       "      <td>91</td>\n",
       "      <td>24</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>Money So Big</td>\n",
       "      <td>Yeat</td>\n",
       "      <td>-</td>\n",
       "      <td>95</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>Blick Blick!</td>\n",
       "      <td>Coi Leray &amp; Nicki Minaj</td>\n",
       "      <td>95</td>\n",
       "      <td>37</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>Fall In Love</td>\n",
       "      <td>Bailey Zimmerman</td>\n",
       "      <td>-</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>X Ultima Vez</td>\n",
       "      <td>Daddy Yankee &amp; Bad Bunny</td>\n",
       "      <td>99</td>\n",
       "      <td>73</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Song_name               Artist_name Last_week_rank Peak_rank  \\\n",
       "0       As It Was              Harry Styles              2         1   \n",
       "1     First Class               Jack Harlow              1         1   \n",
       "2      Heat Waves             Glass Animals              3         1   \n",
       "3      Big Energy                     Latto              4         3   \n",
       "4           Enemy     Imagine Dragons X JID              5         5   \n",
       "..            ...                       ...            ...       ...   \n",
       "195       P Power     Gunna Featuring Drake             91        24   \n",
       "196  Money So Big                      Yeat              -        95   \n",
       "197  Blick Blick!   Coi Leray & Nicki Minaj             95        37   \n",
       "198  Fall In Love          Bailey Zimmerman              -        99   \n",
       "199  X Ultima Vez  Daddy Yankee & Bad Bunny             99        73   \n",
       "\n",
       "    Weeks_on_board  \n",
       "0                3  \n",
       "1                2  \n",
       "2               66  \n",
       "3               26  \n",
       "4               22  \n",
       "..             ...  \n",
       "195             14  \n",
       "196              4  \n",
       "197              4  \n",
       "198              1  \n",
       "199              3  \n",
       "\n",
       "[200 rows x 5 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row_list=driver.find_elements_by_xpath('//li[@class=\"lrv-u-width-100p\"]/ul')\n",
    "len(row_list)\n",
    "j=0\n",
    "for i in range(len(row_list)):\n",
    "\n",
    "    eles = row_list[i].find_elements_by_tag_name('li')\n",
    "    \n",
    "    name=eles[0].text.split('\\n')\n",
    "    \n",
    "    # appending values in lists\n",
    "    \n",
    "    Song_name.append(name[0])   # scarping song name\n",
    "    Artist_name.append(name[1])  # scarping artist name\n",
    "    \n",
    "    Last_week_rank.append(eles[3].text) # scarping Last week rank\n",
    "    Peak_rank.append(eles[4].text)    # scarping peak rank\n",
    "    Weeks_on_board.append(eles[5].text)  # scarping Weeks on board\n",
    "\n",
    "# making dataframe to store values\n",
    "songs_details =pd.DataFrame({'Song_name':Song_name, 'Artist_name':Artist_name, 'Last_week_rank':Last_week_rank, 'Peak_rank':Peak_rank, 'Weeks_on_board':Weeks_on_board})\n",
    "songs_details"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d8187b",
   "metadata": {},
   "source": [
    "**7.** Scrape the details of Data science recruiters from naukri.com.\n",
    "Url = https://www.naukri.com/\n",
    "You have to find the following details:\n",
    "A) Name\n",
    "B) Designation\n",
    "C) Company\n",
    "D) Skills they hire for\n",
    "E) Location\n",
    "Note: - From naukri.com homepage click on the recruiters option and the on the search pane type Data science and\n",
    "click on search. All this should be done through code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "31e0f48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver= webdriver.Chrome(r\"C:\\Users\\nbson\\Downloads\\chromedriver_win32 (3)\\chromedriver.exe\")\n",
    "#connection after uploading driver in jupyter notebook\n",
    "driver=webdriver.Chrome(\"chromedriver.exe\")\n",
    "url = \"https://www.naukri.com/\"\n",
    "driver.get(url)\n",
    "driver.maximize_window()\n",
    "time.sleep(2)\n",
    "\n",
    "#Make empty lists \n",
    "Name=[]  \n",
    "Designation=[] \n",
    "Company=[] \n",
    "Skills=[]  \n",
    "Location=[]\n",
    "\n",
    "\n",
    "search=driver.find_element_by_xpath('//input[@class=\"suggestor-input \"]')\n",
    "search.clear()\n",
    "search.send_keys('Data science')\n",
    "driver.find_element_by_xpath('//div[@class=\"qsbSubmit\"]').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "782e9bc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Designation</th>\n",
       "      <th>Company</th>\n",
       "      <th>Skills</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Opening For Manager / Sr. Manager Data Science</td>\n",
       "      <td>RoleData Scientist</td>\n",
       "      <td>MSD Pharmaceuticals</td>\n",
       "      <td>Key Skills</td>\n",
       "      <td>Pune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HCL || Data Science</td>\n",
       "      <td>RoleData Analyst</td>\n",
       "      <td>HCL Technologies</td>\n",
       "      <td>Key Skills</td>\n",
       "      <td>Chennai, Bangalore/Bengaluru, Delhi / NCR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Science Analyst 2</td>\n",
       "      <td>RoleBusiness Analyst</td>\n",
       "      <td>Epsilon</td>\n",
       "      <td>Key Skills</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Science Analyst</td>\n",
       "      <td>RoleData Analyst</td>\n",
       "      <td>Freelancer Varsha Abhijeet Kakde</td>\n",
       "      <td>Key Skills</td>\n",
       "      <td>Pune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Science Manager</td>\n",
       "      <td>RoleBusiness Analyst</td>\n",
       "      <td>Druva</td>\n",
       "      <td>Key Skills</td>\n",
       "      <td>Pune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Mentor - Data Analyst/Data Science</td>\n",
       "      <td>RoleData Analyst</td>\n",
       "      <td>MarketScope</td>\n",
       "      <td>Key Skills</td>\n",
       "      <td>Kolkata, Mumbai, Visakhapatnam, Hyderabad/Secu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Director - Data Engineering - Data Science Pyt...</td>\n",
       "      <td>RoleHead - Data Science</td>\n",
       "      <td>Optum</td>\n",
       "      <td>Key Skills</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Product Analyst, Google Assistant Data Science</td>\n",
       "      <td>RoleBusiness Analyst</td>\n",
       "      <td>Google</td>\n",
       "      <td>Key Skills</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Analyst: Data Science Insights</td>\n",
       "      <td>RoleData Science &amp; Analytics - Other</td>\n",
       "      <td>TIGER ANALYTICS INDIA CONSULTING PRIVATE LIMITED</td>\n",
       "      <td>Key Skills</td>\n",
       "      <td>Chennai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Hiring For Data Science Intern</td>\n",
       "      <td>RoleData Analyst</td>\n",
       "      <td>FLIP ROBO TECHNOLOGIES PRIVATE LIMITED</td>\n",
       "      <td>Key Skills</td>\n",
       "      <td>Noida, Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Senior Analyst - Data Science</td>\n",
       "      <td>RoleData Analyst</td>\n",
       "      <td>Tiger Analytics India LLP</td>\n",
       "      <td>Key Skills</td>\n",
       "      <td>Chennai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ACN - Applied Intelligence - CC - Data Science...</td>\n",
       "      <td>RoleData Analyst</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>Key Skills</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ACN - Applied Intelligence - CC - Data Science...</td>\n",
       "      <td>RoleData Analyst</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>Key Skills</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Team Lead/Consultant-Data Science</td>\n",
       "      <td>RoleBusiness Analyst</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>Key Skills</td>\n",
       "      <td>Mumbai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Azure Data Science Professional</td>\n",
       "      <td>RoleData Engineer</td>\n",
       "      <td>Objectwin</td>\n",
       "      <td>Key Skills</td>\n",
       "      <td>Chennai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Data Science (OCR &amp; Document Conversion)</td>\n",
       "      <td>RoleData Science &amp; Analytics - Other</td>\n",
       "      <td>BLUCOGNITION PRIVATE LIMITED</td>\n",
       "      <td>Key Skills</td>\n",
       "      <td>Pune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ACN - Applied Intelligence - CC - Data Science...</td>\n",
       "      <td>RoleData Scientist</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>Key Skills</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Name  \\\n",
       "0      Opening For Manager / Sr. Manager Data Science   \n",
       "1                                 HCL || Data Science   \n",
       "2                              Data Science Analyst 2   \n",
       "3                                                   -   \n",
       "4                                Data Science Analyst   \n",
       "5                                Data Science Manager   \n",
       "6                  Mentor - Data Analyst/Data Science   \n",
       "7                                                   -   \n",
       "8   Director - Data Engineering - Data Science Pyt...   \n",
       "9      Product Analyst, Google Assistant Data Science   \n",
       "10                                                  -   \n",
       "11                     Analyst: Data Science Insights   \n",
       "12                     Hiring For Data Science Intern   \n",
       "13                      Senior Analyst - Data Science   \n",
       "14  ACN - Applied Intelligence - CC - Data Science...   \n",
       "15  ACN - Applied Intelligence - CC - Data Science...   \n",
       "16                  Team Lead/Consultant-Data Science   \n",
       "17                    Azure Data Science Professional   \n",
       "18           Data Science (OCR & Document Conversion)   \n",
       "19  ACN - Applied Intelligence - CC - Data Science...   \n",
       "\n",
       "                             Designation  \\\n",
       "0                     RoleData Scientist   \n",
       "1                       RoleData Analyst   \n",
       "2                   RoleBusiness Analyst   \n",
       "3                                      -   \n",
       "4                       RoleData Analyst   \n",
       "5                   RoleBusiness Analyst   \n",
       "6                       RoleData Analyst   \n",
       "7                                      -   \n",
       "8                RoleHead - Data Science   \n",
       "9                   RoleBusiness Analyst   \n",
       "10                                     -   \n",
       "11  RoleData Science & Analytics - Other   \n",
       "12                      RoleData Analyst   \n",
       "13                      RoleData Analyst   \n",
       "14                      RoleData Analyst   \n",
       "15                      RoleData Analyst   \n",
       "16                  RoleBusiness Analyst   \n",
       "17                     RoleData Engineer   \n",
       "18  RoleData Science & Analytics - Other   \n",
       "19                    RoleData Scientist   \n",
       "\n",
       "                                             Company      Skills  \\\n",
       "0                                MSD Pharmaceuticals  Key Skills   \n",
       "1                                   HCL Technologies  Key Skills   \n",
       "2                                            Epsilon  Key Skills   \n",
       "3                                                  -           -   \n",
       "4                   Freelancer Varsha Abhijeet Kakde  Key Skills   \n",
       "5                                              Druva  Key Skills   \n",
       "6                                        MarketScope  Key Skills   \n",
       "7                                                  -           -   \n",
       "8                                              Optum  Key Skills   \n",
       "9                                             Google  Key Skills   \n",
       "10                                                 -           -   \n",
       "11  TIGER ANALYTICS INDIA CONSULTING PRIVATE LIMITED  Key Skills   \n",
       "12            FLIP ROBO TECHNOLOGIES PRIVATE LIMITED  Key Skills   \n",
       "13                         Tiger Analytics India LLP  Key Skills   \n",
       "14                                         Accenture  Key Skills   \n",
       "15                                         Accenture  Key Skills   \n",
       "16                                         Accenture  Key Skills   \n",
       "17                                         Objectwin  Key Skills   \n",
       "18                      BLUCOGNITION PRIVATE LIMITED  Key Skills   \n",
       "19                                         Accenture  Key Skills   \n",
       "\n",
       "                                             Location  \n",
       "0                                                Pune  \n",
       "1           Chennai, Bangalore/Bengaluru, Delhi / NCR  \n",
       "2                                 Bangalore/Bengaluru  \n",
       "3                                                   -  \n",
       "4                                                Pune  \n",
       "5                                                Pune  \n",
       "6   Kolkata, Mumbai, Visakhapatnam, Hyderabad/Secu...  \n",
       "7                                                   -  \n",
       "8                                 Bangalore/Bengaluru  \n",
       "9                                 Bangalore/Bengaluru  \n",
       "10                                                  -  \n",
       "11                                            Chennai  \n",
       "12                         Noida, Bangalore/Bengaluru  \n",
       "13                                            Chennai  \n",
       "14                                   Gurgaon/Gurugram  \n",
       "15                                   Gurgaon/Gurugram  \n",
       "16                                             Mumbai  \n",
       "17                                            Chennai  \n",
       "18                                               Pune  \n",
       "19                                   Gurgaon/Gurugram  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urls=[]\n",
    "links=driver.find_elements_by_xpath('//a[@class=\"title fw500 ellipsis\"]')\n",
    "\n",
    "\n",
    "for i in range(len(links)):\n",
    "    urls.append(links[i].get_attribute('href'))\n",
    "\n",
    "for url in urls:\n",
    "    driver.get(url) \n",
    "    time.sleep(2)\n",
    "   \n",
    "    try:\n",
    "        Designations=driver.find_element_by_xpath('//div[@class=\"details\"]').text\n",
    "        Designation.append(Designations)\n",
    "        \n",
    "    except NoSuchElementException:\n",
    "        Designation.append('-')\n",
    "        \n",
    "    try:\n",
    "        companys=driver.find_element_by_xpath('//div[@class=\"jd-header-comp-name\"]/a[1]').text \n",
    "        Company.append(companys)\n",
    "        \n",
    "    except NoSuchElementException:\n",
    "        Company.append('-')\n",
    "        \n",
    "    try:\n",
    "        name=driver.find_element_by_xpath('//div[@class=\"jd-top-head\"]/header').text\n",
    "        Name.append(name)\n",
    "        \n",
    "    except NoSuchElementException:\n",
    "        Name.append('-')\n",
    "    \n",
    "    try:\n",
    "        Skill=driver.find_element_by_xpath('//div[@class=\"key-skill\"]/div').text\n",
    "        Skills.append(Skill)\n",
    "        \n",
    "    except NoSuchElementException:\n",
    "         Skills.append('-')\n",
    "    try:\n",
    "        Locations=driver.find_element_by_xpath('//span[@class=\"location \"]').text\n",
    "        Location.append(Locations)\n",
    "        \n",
    "    except NoSuchElementException:\n",
    "        Location.append('-')\n",
    "\n",
    "naukari=pd.DataFrame({'Name':Name , 'Designation':Designation,'Company':Company,'Skills':Skills,'Location':Location})\n",
    "naukari"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e7ae97",
   "metadata": {},
   "source": [
    "**8.** Scrape the details of Highest selling novels.\n",
    "Url = https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey\u0002compare/\n",
    "You have to find the following details:\n",
    "A) Book name\n",
    "B) Author name\n",
    "C) Volumes sold\n",
    "D) Publisher\n",
    "E) Genre\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "47f0ee29",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver= webdriver.Chrome(r\"C:\\Users\\nbson\\Downloads\\chromedriver_win32 (3)\\chromedriver.exe\")\n",
    "#connection after uploading driver in jupyter notebook\n",
    "driver=webdriver.Chrome(\"chromedriver.exe\")\n",
    "\n",
    "url='https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare'\n",
    "driver.get(url)\n",
    "driver.maximize_window()\n",
    "time.sleep(2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fd0b07d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book_name</th>\n",
       "      <th>Author_name</th>\n",
       "      <th>Volumes_sold</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Da Vinci Code,The</td>\n",
       "      <td>Brown, Dan</td>\n",
       "      <td>5,094,805</td>\n",
       "      <td>Transworld</td>\n",
       "      <td>Crime, Thriller &amp; Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Harry Potter and the Deathly Hallows</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,475,152</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Harry Potter and the Philosopher's Stone</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,200,654</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Harry Potter and the Order of the Phoenix</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,179,479</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fifty Shades of Grey</td>\n",
       "      <td>James, E. L.</td>\n",
       "      <td>3,758,936</td>\n",
       "      <td>Random House</td>\n",
       "      <td>Romance &amp; Sagas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Ghost,The</td>\n",
       "      <td>Harris, Robert</td>\n",
       "      <td>807,311</td>\n",
       "      <td>Random House</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Happy Days with the Naked Chef</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>794,201</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Hunger Games,The:Hunger Games Trilogy</td>\n",
       "      <td>Collins, Suzanne</td>\n",
       "      <td>792,187</td>\n",
       "      <td>Scholastic Ltd.</td>\n",
       "      <td>Young Adult Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Lost Boy,The:A Foster Child's Search for the L...</td>\n",
       "      <td>Pelzer, Dave</td>\n",
       "      <td>791,507</td>\n",
       "      <td>Orion</td>\n",
       "      <td>Biography: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Jamie's Ministry of Food:Anyone Can Learn to C...</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>791,095</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Book_name       Author_name  \\\n",
       "0                                   Da Vinci Code,The        Brown, Dan   \n",
       "1                Harry Potter and the Deathly Hallows     Rowling, J.K.   \n",
       "2            Harry Potter and the Philosopher's Stone     Rowling, J.K.   \n",
       "3           Harry Potter and the Order of the Phoenix     Rowling, J.K.   \n",
       "4                                Fifty Shades of Grey      James, E. L.   \n",
       "..                                                ...               ...   \n",
       "95                                          Ghost,The    Harris, Robert   \n",
       "96                     Happy Days with the Naked Chef     Oliver, Jamie   \n",
       "97              Hunger Games,The:Hunger Games Trilogy  Collins, Suzanne   \n",
       "98  Lost Boy,The:A Foster Child's Search for the L...      Pelzer, Dave   \n",
       "99  Jamie's Ministry of Food:Anyone Can Learn to C...     Oliver, Jamie   \n",
       "\n",
       "   Volumes_sold        Publisher                        Genre  \n",
       "0     5,094,805       Transworld  Crime, Thriller & Adventure  \n",
       "1     4,475,152       Bloomsbury           Children's Fiction  \n",
       "2     4,200,654       Bloomsbury           Children's Fiction  \n",
       "3     4,179,479       Bloomsbury           Children's Fiction  \n",
       "4     3,758,936     Random House              Romance & Sagas  \n",
       "..          ...              ...                          ...  \n",
       "95      807,311     Random House   General & Literary Fiction  \n",
       "96      794,201          Penguin        Food & Drink: General  \n",
       "97      792,187  Scholastic Ltd.          Young Adult Fiction  \n",
       "98      791,507            Orion           Biography: General  \n",
       "99      791,095          Penguin        Food & Drink: General  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Make empty lists \n",
    "Book_name=[]\n",
    "Author_name=[]\n",
    "Volumes_sold =[]\n",
    "Publisher = []\n",
    "Genre=[]\n",
    "\n",
    "\n",
    "# extracting rows\n",
    "rows= driver.find_elements_by_xpath('//table[@class=\"in-article sortable\"]/tbody/tr')\n",
    "for i in rows:\n",
    "    \n",
    "    cols = i.find_elements_by_tag_name('td')  # extracting allcolumns data\n",
    "    Book_name.append(cols[1].text)            #appending bookname to list\n",
    "    Author_name.append(cols[2].text)          #appending Author_name to list\n",
    "    Volumes_sold.append(cols[3].text)         #appending Volumes_sold to list\n",
    "    Publisher.append(cols[4].text)            #appending Publisher to list\n",
    "    Genre.append(cols[5].text)                #appending Genre to list\n",
    "    \n",
    "# storing data in dataframe \n",
    "Books_records=pd.DataFrame({'Book_name':Book_name , 'Author_name':Author_name,'Volumes_sold':Volumes_sold,'Publisher':Publisher,'Genre':Genre})\n",
    "Books_records"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "384de1e6",
   "metadata": {},
   "source": [
    "**9.** Scrape the details most watched tv series of all time from imdb.com.\n",
    "Url = https://www.imdb.com/list/ls095964455/\n",
    "You have to find the following details:\n",
    "A) Name\n",
    "B) Year span\n",
    "C) Genre\n",
    "D) Run time\n",
    "E) Ratings\n",
    "F) Votes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7dbb39af",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver= webdriver.Chrome(r\"C:\\Users\\nbson\\Downloads\\chromedriver_win32 (3)\\chromedriver.exe\")\n",
    "#connection after uploading driver in jupyter notebook\n",
    "driver=webdriver.Chrome(\"chromedriver.exe\")\n",
    "url = \" https://www.imdb.com/list/ls095964455/\"\n",
    "driver.get(url)\n",
    "driver.maximize_window()\n",
    "time.sleep(2)\n",
    "\n",
    "#Make empty lists \n",
    "Name=[]\n",
    "Year_span=[]\n",
    "Genre =[]\n",
    "Run_time = []\n",
    "Ratings=[]\n",
    "Votes=[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6c8baaf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "100 100 100 100 100\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Year_span</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Run_time</th>\n",
       "      <th>Votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Game of Thrones</td>\n",
       "      <td>2011–2019</td>\n",
       "      <td>Action, Adventure, Drama</td>\n",
       "      <td>57 min</td>\n",
       "      <td>1,979,331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stranger Things</td>\n",
       "      <td>2016–</td>\n",
       "      <td>Drama, Fantasy, Horror</td>\n",
       "      <td>51 min</td>\n",
       "      <td>984,999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Walking Dead</td>\n",
       "      <td>2010–2022</td>\n",
       "      <td>Drama, Horror, Thriller</td>\n",
       "      <td>44 min</td>\n",
       "      <td>943,424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13 Reasons Why</td>\n",
       "      <td>2017–2020</td>\n",
       "      <td>Drama, Mystery, Thriller</td>\n",
       "      <td>60 min</td>\n",
       "      <td>281,837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The 100</td>\n",
       "      <td>2014–2020</td>\n",
       "      <td>Drama, Mystery, Sci-Fi</td>\n",
       "      <td>43 min</td>\n",
       "      <td>241,786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Reign</td>\n",
       "      <td>2013–2017</td>\n",
       "      <td>Drama, Fantasy</td>\n",
       "      <td>42 min</td>\n",
       "      <td>48,503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>A Series of Unfortunate Events</td>\n",
       "      <td>2017–2019</td>\n",
       "      <td>Adventure, Comedy, Drama</td>\n",
       "      <td>50 min</td>\n",
       "      <td>59,138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Criminal Minds</td>\n",
       "      <td>2005–2020</td>\n",
       "      <td>Crime, Drama, Mystery</td>\n",
       "      <td>42 min</td>\n",
       "      <td>188,612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Scream: The TV Series</td>\n",
       "      <td>2015–2019</td>\n",
       "      <td>Comedy, Crime, Drama</td>\n",
       "      <td>45 min</td>\n",
       "      <td>39,971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>The Haunting of Hill House</td>\n",
       "      <td>2018</td>\n",
       "      <td>Drama, Horror, Mystery</td>\n",
       "      <td>572 min</td>\n",
       "      <td>226,087</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Name  Year_span                     Genre  \\\n",
       "0                   Game of Thrones   2011–2019  Action, Adventure, Drama   \n",
       "1                   Stranger Things      2016–     Drama, Fantasy, Horror   \n",
       "2                  The Walking Dead   2010–2022   Drama, Horror, Thriller   \n",
       "3                    13 Reasons Why   2017–2020  Drama, Mystery, Thriller   \n",
       "4                           The 100   2014–2020    Drama, Mystery, Sci-Fi   \n",
       "..                               ...        ...                       ...   \n",
       "95                            Reign   2013–2017            Drama, Fantasy   \n",
       "96   A Series of Unfortunate Events   2017–2019  Adventure, Comedy, Drama   \n",
       "97                   Criminal Minds   2005–2020     Crime, Drama, Mystery   \n",
       "98            Scream: The TV Series   2015–2019      Comedy, Crime, Drama   \n",
       "99       The Haunting of Hill House        2018    Drama, Horror, Mystery   \n",
       "\n",
       "   Run_time      Votes  \n",
       "0    57 min  1,979,331  \n",
       "1    51 min    984,999  \n",
       "2    44 min    943,424  \n",
       "3    60 min    281,837  \n",
       "4    43 min    241,786  \n",
       "..      ...        ...  \n",
       "95   42 min     48,503  \n",
       "96   50 min     59,138  \n",
       "97   42 min    188,612  \n",
       "98   45 min     39,971  \n",
       "99  572 min    226,087  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series_list =driver.find_elements_by_xpath('//div[@class=\"lister-list\"]/div')\n",
    "\n",
    "\n",
    "name=driver.find_elements_by_xpath('//h3[@class=\"lister-item-header\"]')  # scraping name and year span\n",
    "\n",
    "genre=driver.find_elements_by_xpath('//span[@class=\"genre\"]')   # scraping name and year span\n",
    "\n",
    "runTimes =driver.find_elements_by_xpath('//span[@class=\"runtime\"]')   # scraping name and run time\n",
    "\n",
    "ratings =driver.find_elements_by_xpath('//div[@class=\"ipl-rating-star small\"]')    # scraping name and rating\n",
    "\n",
    "votes =driver.find_elements_by_xpath('//span[@name=\"nv\"]')      # scraping name and votes\n",
    "\n",
    "\n",
    "for i in range(len(name)):\n",
    "    # extracting name and year span from name list\n",
    "    Name.append(name[i].text.split('(')[0].split('.')[1])\n",
    "    Year_span.append(name[i].text.split('(')[1].split(')')[0])\n",
    "    \n",
    "    Genre.append(genre[i].text)   # appending genre\n",
    "    Run_time.append(runTimes[i].text)   # appending Run_time\n",
    "    Ratings.append(ratings[i].text)   # appending Ratings\n",
    "    Votes.append(votes[i].text)   # appending Votes\n",
    "# dispalying length of all lists\n",
    "print(len(Name),len(Year_span),len(Genre),len(Run_time),len(Votes))   \n",
    "# storing data in datframe.\n",
    "top_100_series = pd.DataFrame({'Name':Name ,'Year_span':Year_span ,'Genre':Genre ,'Run_time':Run_time ,'Votes':Votes})\n",
    "top_100_series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aef0f0d",
   "metadata": {},
   "source": [
    "**10.** Details of Datasets from UCI machine learning repositories.\n",
    "Url = https://archive.ics.uci.edu/\n",
    "You have to find the following details:\n",
    "A) Dataset name\n",
    "B) Data type\n",
    "C) Task\n",
    "D) Attribute type\n",
    "E) No of instances\n",
    "F) No of attribute\n",
    "G) Year\n",
    "Note: - from the home page you have to go to the ShowAllDataset page through code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4c6eaa6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver= webdriver.Chrome(r\"C:\\Users\\nbson\\Downloads\\chromedriver_win32 (3)\\chromedriver.exe\")\n",
    "#connection after uploading driver in jupyter notebook\n",
    "driver=webdriver.Chrome(\"chromedriver.exe\")\n",
    "url = \"https://archive.ics.uci.edu/ \"\n",
    "driver.get(url)\n",
    "driver.maximize_window()\n",
    "time.sleep(2)\n",
    "\n",
    "#Make empty lists \n",
    "Dataset_name=[]\n",
    "Data_type=[]\n",
    "Task =[]\n",
    "Attribute_type = []\n",
    "No_of_instances=[]\n",
    "No_of_attribute=[]\n",
    "Year=[]\n",
    "\n",
    "# clicking view all dataset\n",
    "driver.find_element_by_xpath('/html/body/table[1]/tbody/tr/td[2]/span[2]').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "0c2b0149",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset_name</th>\n",
       "      <th>Data_type</th>\n",
       "      <th>Task</th>\n",
       "      <th>Attribute_type</th>\n",
       "      <th>No_of_instances</th>\n",
       "      <th>No_of_attribute</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abalone</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>4177</td>\n",
       "      <td>8</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adult</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer</td>\n",
       "      <td>48842</td>\n",
       "      <td>14</td>\n",
       "      <td>1996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Annealing</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>798</td>\n",
       "      <td>38</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Anonymous Microsoft Web Data</td>\n",
       "      <td></td>\n",
       "      <td>Recommender-Systems</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>37711</td>\n",
       "      <td>294</td>\n",
       "      <td>1998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Arrhythmia</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>452</td>\n",
       "      <td>279</td>\n",
       "      <td>1998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617</th>\n",
       "      <td>Influenza outbreak event prediction via Twitte...</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>75840</td>\n",
       "      <td>525</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>618</th>\n",
       "      <td>Turkish Music Emotion Dataset</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>400</td>\n",
       "      <td>50</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619</th>\n",
       "      <td>Maternal Health Risk Data Set</td>\n",
       "      <td></td>\n",
       "      <td>Classification</td>\n",
       "      <td></td>\n",
       "      <td>1014</td>\n",
       "      <td>7</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620</th>\n",
       "      <td>Room Occupancy Estimation</td>\n",
       "      <td>Multivariate, Time-Series</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real</td>\n",
       "      <td>10129</td>\n",
       "      <td>16</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621</th>\n",
       "      <td>Image Recognition Task Execution Times in Mobi...</td>\n",
       "      <td>Univariate</td>\n",
       "      <td>Regression</td>\n",
       "      <td>Real</td>\n",
       "      <td>4000</td>\n",
       "      <td>2</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>622 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Dataset_name  \\\n",
       "0                                              Abalone   \n",
       "1                                                Adult   \n",
       "2                                            Annealing   \n",
       "3                         Anonymous Microsoft Web Data   \n",
       "4                                           Arrhythmia   \n",
       "..                                                 ...   \n",
       "617  Influenza outbreak event prediction via Twitte...   \n",
       "618                      Turkish Music Emotion Dataset   \n",
       "619                      Maternal Health Risk Data Set   \n",
       "620                          Room Occupancy Estimation   \n",
       "621  Image Recognition Task Execution Times in Mobi...   \n",
       "\n",
       "                      Data_type                  Task  \\\n",
       "0                 Multivariate        Classification    \n",
       "1                 Multivariate        Classification    \n",
       "2                 Multivariate        Classification    \n",
       "3                                Recommender-Systems    \n",
       "4                 Multivariate        Classification    \n",
       "..                          ...                   ...   \n",
       "617               Multivariate        Classification    \n",
       "618               Multivariate        Classification    \n",
       "619                                   Classification    \n",
       "620  Multivariate, Time-Series        Classification    \n",
       "621                 Univariate            Regression    \n",
       "\n",
       "                  Attribute_type No_of_instances No_of_attribute   Year  \n",
       "0    Categorical, Integer, Real            4177               8   1995   \n",
       "1          Categorical, Integer           48842              14   1996   \n",
       "2    Categorical, Integer, Real             798              38          \n",
       "3                   Categorical           37711             294   1998   \n",
       "4    Categorical, Integer, Real             452             279   1998   \n",
       "..                           ...             ...             ...    ...  \n",
       "617               Integer, Real           75840             525   2020   \n",
       "618               Integer, Real             400              50   2020   \n",
       "619                                        1014               7   2020   \n",
       "620                        Real           10129              16   2021   \n",
       "621                        Real            4000               2   2021   \n",
       "\n",
       "[622 rows x 7 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "year=driver.find_elements_by_xpath('/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr')\n",
    "for i in year :\n",
    "    cols=i.find_elements_by_tag_name('td')\n",
    "    if len(cols)==9:\n",
    "        Dataset_name.append(cols[2].text)\n",
    "        Data_type.append(cols[3].text)\n",
    "        Task.append(cols[4].text)\n",
    "        Attribute_type.append(cols[5].text)\n",
    "        No_of_instances.append(cols[6].text)\n",
    "        No_of_attribute.append(cols[7].text)\n",
    "        Year.append(cols[8].text)\n",
    "# storing values in dataframe\n",
    "dataset_details=pd.DataFrame({'Dataset_name':Dataset_name , 'Data_type':Data_type , 'Task':Task ,\n",
    "                             'Attribute_type':Attribute_type , 'No_of_instances':No_of_instances ,\n",
    "                             'No_of_attribute':No_of_attribute , 'Year':Year })\n",
    "\n",
    "#displaying records\n",
    "dataset_details"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
