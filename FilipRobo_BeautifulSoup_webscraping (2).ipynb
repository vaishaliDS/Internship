{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1b63a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb4c4319",
   "metadata": {},
   "source": [
    "# 1) Write a python program to display all the header tags from wikipedia.org.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec421015",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url=\"https://www.wikipedia.org/\"\n",
    "page=requests.get(url)\n",
    "page\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6434a42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup=BeautifulSoup(page.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da54a102",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h1 Tag Header content is :-\n",
      "\n",
      "\n",
      "Wikipedia\n",
      "\n",
      "The Free Encyclopedia\n",
      "\n",
      "-------------------\n",
      "h2 Tag Header content is :-\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "1 000 000+\n",
      "\n",
      "\n",
      "articles\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100 000+\n",
      "\n",
      "\n",
      "articles\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "10 000+\n",
      "\n",
      "\n",
      "articles\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "1 000+\n",
      "\n",
      "\n",
      "articles\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100+\n",
      "\n",
      "\n",
      "articles\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "-------------------\n",
      "-------------------\n"
     ]
    }
   ],
   "source": [
    "#list of header tags\n",
    "#d_all('h1',class_=\"mw-parser-outputr\").find('span' ,class_=\"central-textlogo__image sprite svg-Wikipedia_wordmark\").get_text()\n",
    "#[class=\"mp-h2\"]\n",
    "header_tags=['h1','h2' ,'h3']\n",
    "for i in header_tags:\n",
    "    \n",
    "    header =[]\n",
    "    header =soup.find_all(i)\n",
    "    j=0\n",
    "    for k  in header:\n",
    "        j=j+1\n",
    "        if(j==1):\n",
    "            print(i,'Tag Header content is :-')\n",
    "        print(k.get_text())\n",
    "    print('-------------------')\n",
    "\n",
    "                       \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c73bf3",
   "metadata": {},
   "source": [
    "# 2. Write a python program to display IMDB’s Top rated 100 movies’ data (i.e. name, rating, year of release) and make data frame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "012fe68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"https://www.imdb.com/chart/top/?ref_=nv_mv_250\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1223e03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page=requests.get(url)\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "76f7bb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup=BeautifulSoup(page.text,'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af9f1320",
   "metadata": {},
   "outputs": [],
   "source": [
    "#soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "74aa5aa5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data=soup.find('tbody',class_='lister-list')\n",
    "#data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4cabf213",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data=data.find_all('tr')\n",
    "#data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0d07fb61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Year of Release</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Shawshank Redemption</td>\n",
       "      <td>9.2</td>\n",
       "      <td>(1994)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21750</th>\n",
       "      <td>The Shawshank Redemption</td>\n",
       "      <td>9.2</td>\n",
       "      <td>(1994)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20001</th>\n",
       "      <td>The Godfather</td>\n",
       "      <td>9.2</td>\n",
       "      <td>(1972)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20250</th>\n",
       "      <td>The Shawshank Redemption</td>\n",
       "      <td>9.2</td>\n",
       "      <td>(1994)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20251</th>\n",
       "      <td>The Godfather</td>\n",
       "      <td>9.2</td>\n",
       "      <td>(1972)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27500</th>\n",
       "      <td>The Shawshank Redemption</td>\n",
       "      <td>9.2</td>\n",
       "      <td>(1994)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24001</th>\n",
       "      <td>The Godfather</td>\n",
       "      <td>9.2</td>\n",
       "      <td>(1972)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24250</th>\n",
       "      <td>The Shawshank Redemption</td>\n",
       "      <td>9.2</td>\n",
       "      <td>(1994)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24251</th>\n",
       "      <td>The Godfather</td>\n",
       "      <td>9.2</td>\n",
       "      <td>(1972)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24500</th>\n",
       "      <td>The Shawshank Redemption</td>\n",
       "      <td>9.2</td>\n",
       "      <td>(1994)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Title  Ratings Year of Release\n",
       "0      The Shawshank Redemption      9.2          (1994)\n",
       "21750  The Shawshank Redemption      9.2          (1994)\n",
       "20001             The Godfather      9.2          (1972)\n",
       "20250  The Shawshank Redemption      9.2          (1994)\n",
       "20251             The Godfather      9.2          (1972)\n",
       "...                         ...      ...             ...\n",
       "27500  The Shawshank Redemption      9.2          (1994)\n",
       "24001             The Godfather      9.2          (1972)\n",
       "24250  The Shawshank Redemption      9.2          (1994)\n",
       "24251             The Godfather      9.2          (1972)\n",
       "24500  The Shawshank Redemption      9.2          (1994)\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title=[]\n",
    "rating=[]\n",
    "year_of_release=[]\n",
    "\n",
    "for movie in data:\n",
    "    \n",
    "     for movie in data:\n",
    "\n",
    "        title.append(movie.find('td',class_=\"titleColumn\").find('a').get_text())\n",
    "\n",
    "        rating.append(float(movie.find('td',class_='ratingColumn imdbRating').find('strong').get_text()))\n",
    "\n",
    "        year_of_release.append(movie.find('td',class_=\"titleColumn\").find('span',class_='secondaryInfo').get_text())\n",
    "\n",
    " #dict. formation\n",
    "data={'Title':title ,\n",
    "      'Ratings':rating,\n",
    "      'Year of Release':year_of_release}\n",
    "    \n",
    "        \n",
    "    # Making movies dataframe\n",
    "movies_df= pd.DataFrame(data)  \n",
    "movies_df\n",
    "\n",
    "    #Sorting data to get rating descending order \n",
    "df=movies_df.sort_values(by=['Ratings'] ,ascending=False)\n",
    "\n",
    "    #displaying top 100 movies data\n",
    "Top_Hundread_Movies_df=df.head(100)\n",
    "Top_Hundread_Movies_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5369c5c3",
   "metadata": {},
   "source": [
    "# *** Using Function extracting Top 100 Movies data ***\n",
    "\n",
    "2. Write a python program to display IMDB’s Top rated 100 movies’ data (i.e. name, rating, year of release) and make data frame.\n",
    "\n",
    "3. Write a python program to display IMDB’s Top rated 100 Indian movies’ data (i.e. name, rating, year of release) and make data frame.¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "806dd33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getting_Hundred_top_rated_movie_data(url):\n",
    "    page=requests.get(url)\n",
    "    page\n",
    "    soup=BeautifulSoup(page.text,'html.parser')\n",
    "    data=soup.find('tbody',class_='lister-list')\n",
    "    data\n",
    "    data=data.find_all('tr')\n",
    "    data\n",
    "    title=[]\n",
    "    rating=[]\n",
    "    year_of_release=[]\n",
    "\n",
    "    for movie in data:\n",
    "\n",
    "        title.append(movie.find('td',class_=\"titleColumn\").find('a').get_text())\n",
    "\n",
    "        rating.append(float(movie.find('td',class_='ratingColumn imdbRating').find('strong').get_text()))\n",
    "\n",
    "        year_of_release.append(movie.find('td',class_=\"titleColumn\").find('span',class_='secondaryInfo').get_text())\n",
    "\n",
    "    #dict. formation\n",
    "    data={'Title':title ,\n",
    "           'Ratings':rating,\n",
    "          'Year of Release':year_of_release}\n",
    "    \n",
    "        \n",
    "    # Making movies dataframe\n",
    "    movies_df= pd.DataFrame(data)  \n",
    "    movies_df\n",
    "\n",
    "    #Sorting data to get rating descending order \n",
    "    df=movies_df.sort_values(by=['Ratings'] ,ascending=False)\n",
    "\n",
    "    #displaying top 100 movies data\n",
    "    Top_Hundred_Movies_df=df.head(100)\n",
    "    Top_Hundred_Movies_df\n",
    "\n",
    "    return Top_Hundred_Movies_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "425c44aa",
   "metadata": {},
   "source": [
    "# 2. Extracting IMDB’s Top rated 100 movies calling function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8b1f374f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMDB’s Top rated 100 movies :\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Year of Release</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Shawshank Redemption</td>\n",
       "      <td>9.2</td>\n",
       "      <td>(1994)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Godfather</td>\n",
       "      <td>9.2</td>\n",
       "      <td>(1972)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Dark Knight</td>\n",
       "      <td>9.0</td>\n",
       "      <td>(2008)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Godfather: Part II</td>\n",
       "      <td>9.0</td>\n",
       "      <td>(1974)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12 Angry Men</td>\n",
       "      <td>9.0</td>\n",
       "      <td>(1957)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>Inglourious Basterds</td>\n",
       "      <td>8.3</td>\n",
       "      <td>(2009)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>Das Boot</td>\n",
       "      <td>8.3</td>\n",
       "      <td>(1981)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>Avengers: Endgame</td>\n",
       "      <td>8.3</td>\n",
       "      <td>(2019)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>Mononoke-hime</td>\n",
       "      <td>8.3</td>\n",
       "      <td>(1997)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>Once Upon a Time in America</td>\n",
       "      <td>8.3</td>\n",
       "      <td>(1984)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Title  Ratings Year of Release\n",
       "0      The Shawshank Redemption      9.2          (1994)\n",
       "1                 The Godfather      9.2          (1972)\n",
       "2               The Dark Knight      9.0          (2008)\n",
       "3        The Godfather: Part II      9.0          (1974)\n",
       "4                  12 Angry Men      9.0          (1957)\n",
       "..                          ...      ...             ...\n",
       "76         Inglourious Basterds      8.3          (2009)\n",
       "77                     Das Boot      8.3          (1981)\n",
       "78            Avengers: Endgame      8.3          (2019)\n",
       "79                Mononoke-hime      8.3          (1997)\n",
       "80  Once Upon a Time in America      8.3          (1984)\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "print(\"IMDB’s Top rated 100 movies :\")\n",
    "movie_data= getting_Hundred_top_rated_movie_data(\"https://www.imdb.com/chart/top/?ref_=nv_mv_250\") \n",
    "movie_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28407e69",
   "metadata": {},
   "source": [
    "# 3. Extracting IMDB’s Top rated 100 Indian movies by calling function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f9781231",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMDB’s Top rated 100 Indian movies :\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Year of Release</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jai Bhim</td>\n",
       "      <td>8.5</td>\n",
       "      <td>(2021)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3 Idiots</td>\n",
       "      <td>8.4</td>\n",
       "      <td>(2009)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Anbe Sivam</td>\n",
       "      <td>8.4</td>\n",
       "      <td>(2003)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>Pariyerum Perumal</td>\n",
       "      <td>8.4</td>\n",
       "      <td>(2018)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>Golmaal</td>\n",
       "      <td>8.4</td>\n",
       "      <td>(1979)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Bajrangi Bhaijaan</td>\n",
       "      <td>8.0</td>\n",
       "      <td>(2015)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>A Wednesday</td>\n",
       "      <td>8.0</td>\n",
       "      <td>(2008)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>Roja</td>\n",
       "      <td>8.0</td>\n",
       "      <td>(1992)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>Nil Battey Sannata</td>\n",
       "      <td>8.0</td>\n",
       "      <td>(2015)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Dil Chahta Hai</td>\n",
       "      <td>8.0</td>\n",
       "      <td>(2001)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Title  Ratings Year of Release\n",
       "4              Jai Bhim      8.5          (2021)\n",
       "0              3 Idiots      8.4          (2009)\n",
       "99           Anbe Sivam      8.4          (2003)\n",
       "122   Pariyerum Perumal      8.4          (2018)\n",
       "106             Golmaal      8.4          (1979)\n",
       "..                  ...      ...             ...\n",
       "16    Bajrangi Bhaijaan      8.0          (2015)\n",
       "21          A Wednesday      8.0          (2008)\n",
       "140                Roja      8.0          (1992)\n",
       "204  Nil Battey Sannata      8.0          (2015)\n",
       "23       Dil Chahta Hai      8.0          (2001)\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extracting \n",
    "print(\"IMDB’s Top rated 100 Indian movies :\")\n",
    "movie_dict= getting_Hundred_top_rated_movie_data(\"https://www.imdb.com/india/top-rated-indian-movies/?sort=nv,desc&mode=simple&page=1\") \n",
    "movie_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf5f8a5",
   "metadata": {},
   "source": [
    "# 4) Write a python program to scrape product name, price and discounts from https://meesho.com/bags\u0002ladies/pl/p7vbp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1a80adb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product Name</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ravishing Fancy Women Handbags</td>\n",
       "      <td>₹201</td>\n",
       "      <td>₹86 discount on 1st order</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Trendy Fancy Women Handbags</td>\n",
       "      <td>₹199</td>\n",
       "      <td>₹85 discount on 1st order</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gorgeous Stylish Women Handbags</td>\n",
       "      <td>₹150</td>\n",
       "      <td>₹63 discount on 1st order</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gorgeous Classy Women Handbags</td>\n",
       "      <td>₹187</td>\n",
       "      <td>₹79 discount on 1st order</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Voguish Fashionable Women Handbags</td>\n",
       "      <td>₹227</td>\n",
       "      <td>₹97 discount on 1st order</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Elegant Fancy Women's Bags</td>\n",
       "      <td>₹181</td>\n",
       "      <td>₹77 discount on 1st order</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Voguish Classy Women Handbags</td>\n",
       "      <td>₹257</td>\n",
       "      <td>₹100 discount on 1st order</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Elegant Stylish Women Handbags</td>\n",
       "      <td>₹210</td>\n",
       "      <td>₹89 discount on 1st order</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Elegant Fancy Women'S Pu Leather Hand Bags</td>\n",
       "      <td>₹164</td>\n",
       "      <td>₹70 discount on 1st order</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Wonderful Women Women Handbags</td>\n",
       "      <td>₹206</td>\n",
       "      <td>₹88 discount on 1st order</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Elite Fancy Women Handbags</td>\n",
       "      <td>₹137</td>\n",
       "      <td>₹58 discount on 1st order</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Voguish Alluring Women Handbags</td>\n",
       "      <td>₹469</td>\n",
       "      <td>₹100 discount on 1st order</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Elegant Versatile Women Handbags</td>\n",
       "      <td>₹142</td>\n",
       "      <td>₹60 discount on 1st order</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Classic Attractive Women Handbag</td>\n",
       "      <td>₹197</td>\n",
       "      <td>₹84 discount on 1st order</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Gorgeous Versatile Women Handbags</td>\n",
       "      <td>₹201</td>\n",
       "      <td>₹85 discount on 1st order</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Elegant Attractive Women Handbags</td>\n",
       "      <td>₹171</td>\n",
       "      <td>₹72 discount on 1st order</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Graceful Attractive Women Handbags</td>\n",
       "      <td>₹179</td>\n",
       "      <td>₹76 discount on 1st order</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Gorgeous Alluring Women Handbags</td>\n",
       "      <td>₹176</td>\n",
       "      <td>₹75 discount on 1st order</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Elite Fancy Women Handbags</td>\n",
       "      <td>₹234</td>\n",
       "      <td>₹99 discount on 1st order</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Gorgeous Versatile Women Handbags</td>\n",
       "      <td>₹180</td>\n",
       "      <td>₹76 discount on 1st order</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Product Name  Price  \\\n",
       "0               Ravishing Fancy Women Handbags  ₹201   \n",
       "1                  Trendy Fancy Women Handbags  ₹199   \n",
       "2              Gorgeous Stylish Women Handbags  ₹150   \n",
       "3               Gorgeous Classy Women Handbags  ₹187   \n",
       "4           Voguish Fashionable Women Handbags  ₹227   \n",
       "5                   Elegant Fancy Women's Bags  ₹181   \n",
       "6                Voguish Classy Women Handbags  ₹257   \n",
       "7               Elegant Stylish Women Handbags  ₹210   \n",
       "8   Elegant Fancy Women'S Pu Leather Hand Bags  ₹164   \n",
       "9               Wonderful Women Women Handbags  ₹206   \n",
       "10                  Elite Fancy Women Handbags  ₹137   \n",
       "11             Voguish Alluring Women Handbags  ₹469   \n",
       "12            Elegant Versatile Women Handbags  ₹142   \n",
       "13            Classic Attractive Women Handbag  ₹197   \n",
       "14           Gorgeous Versatile Women Handbags  ₹201   \n",
       "15           Elegant Attractive Women Handbags  ₹171   \n",
       "16          Graceful Attractive Women Handbags  ₹179   \n",
       "17            Gorgeous Alluring Women Handbags  ₹176   \n",
       "18                  Elite Fancy Women Handbags  ₹234   \n",
       "19           Gorgeous Versatile Women Handbags  ₹180   \n",
       "\n",
       "                      Discount  \n",
       "0    ₹86 discount on 1st order  \n",
       "1    ₹85 discount on 1st order  \n",
       "2    ₹63 discount on 1st order  \n",
       "3    ₹79 discount on 1st order  \n",
       "4    ₹97 discount on 1st order  \n",
       "5    ₹77 discount on 1st order  \n",
       "6   ₹100 discount on 1st order  \n",
       "7    ₹89 discount on 1st order  \n",
       "8    ₹70 discount on 1st order  \n",
       "9    ₹88 discount on 1st order  \n",
       "10   ₹58 discount on 1st order  \n",
       "11  ₹100 discount on 1st order  \n",
       "12   ₹60 discount on 1st order  \n",
       "13   ₹84 discount on 1st order  \n",
       "14   ₹85 discount on 1st order  \n",
       "15   ₹72 discount on 1st order  \n",
       "16   ₹76 discount on 1st order  \n",
       "17   ₹75 discount on 1st order  \n",
       "18   ₹99 discount on 1st order  \n",
       "19   ₹76 discount on 1st order  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_ItemText(ls):\n",
    "    for i in ls : \n",
    "        if(ls==name1):\n",
    "            name.append(i.get_text())\n",
    "           \n",
    "        elif ls==price1 :\n",
    "            price.append(i.get_text())\n",
    "       \n",
    "        else:\n",
    "            discount.append(i.get_text())\n",
    "           \n",
    "\n",
    "url = 'https://meesho.com/bags\u0002ladies/pl/p7vbp'\n",
    "page= requests.get(url)\n",
    "\n",
    "soup=BeautifulSoup(page.content)\n",
    "\n",
    "# Making blank lists for name , price , discount \n",
    "name = []\n",
    "price = []\n",
    "discount =[]\n",
    "Item_details = {}\n",
    "\n",
    "# Extracting product names\n",
    "name1 = soup.find_all('p', class_='Text__StyledText-sc-oo0kvp-0 bWSOET NewProductCard__ProductTitle_Desktop-sc-j0e7tu-4 cQhePS NewProductCard__ProductTitle_Desktop-sc-j0e7tu-4 cQhePS')\n",
    "\n",
    "# Extracting Prices\n",
    "price1 = soup.find_all('h5' , class_='Text__StyledText-sc-oo0kvp-0 hiHdyy')\n",
    "\n",
    "# Extracting Discount\n",
    "discount1 = soup.find_all('p',class_='Text__StyledText-sc-oo0kvp-0 fCJVtz NewProductCard__DiscountTextParagraph-sc-j0e7tu-16 kmYsnm NewProductCard__DiscountTextParagraph-sc-j0e7tu-16 kmYsnm')\n",
    "\n",
    "# calling the function to append items in lists\n",
    "get_ItemText(name1)\n",
    "get_ItemText(price1)\n",
    "get_ItemText(discount1)\n",
    "\n",
    "#MAking Item Dictionary\n",
    "Item_details ={'Product Name ' : name ,\n",
    "               'Price' : price ,\n",
    "                'Discount' :discount}\n",
    " # Making Datframe of Item Details\n",
    "df=pd.DataFrame(Item_details)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad8b8b3",
   "metadata": {},
   "source": [
    "# 5) Write a python program to scrape cricket rankings from icc-cricket.com. You have to scrape:\n",
    "a) Top 10 ODI teams in men’s cricket along with the records for matches, points and rating.\n",
    "b) Top 10 ODI Batsmen along with the records of their team and rating.\n",
    "c) Top 10 ODI bowlers along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "36136ae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 ODI teams in men’s cricket along with the records for matches, points and rating.\n",
      "  \n",
      "  Team_ranking        Team_name Matches Points Ratings\n",
      "0            1   New Zealand NZ      17  2,054     121\n",
      "1            2      England ENG      32  3,793     119\n",
      "2            3    Australia AUS      28  3,244     116\n",
      "3            4        India IND      38  4,162     110\n",
      "4            5  South Africa SA      28  2,943     105\n",
      "5            6     Pakistan PAK      27  2,524      93\n",
      "6            7   Bangladesh BAN      33  2,988      91\n",
      "7            8     Sri Lanka SL      35  2,835      81\n",
      "8            9   West Indies WI      36  2,788      77\n",
      "9           10  Afghanistan AFG      23  1,562      68\n"
     ]
    }
   ],
   "source": [
    "# 5.a) Top 10 ODI teams in men’s cricket along with the records for matches, points and rating.\n",
    "\n",
    "team_details={'Team_ranking' :[],\n",
    "               'Team_name' :[],\n",
    "                'Matches' :[],\n",
    "                'Points' :[],\n",
    "                'Ratings' :[]}\n",
    "#function call\n",
    "print(\"Top 10 ODI teams in men’s cricket along with the records for matches, points and rating.\")\n",
    "print(\"  \")\n",
    "url = 'https://www.icc-cricket.com/rankings/mens/team-rankings/odi'\n",
    "\n",
    "\n",
    "page= requests.get(url)\n",
    "soup=BeautifulSoup(page.text, 'html.parser')\n",
    "\n",
    "ranking_table= soup.find('table' , class_='table')\n",
    "    #print(ranking_table)\n",
    "\n",
    "\n",
    "for rank in ranking_table.find_all('tbody'):\n",
    "    rows = rank.find_all('tr')\n",
    "\n",
    "    #selecting top 10 records only to display by rows[0:10]\n",
    "    for row in rows[0:10]:\n",
    "\n",
    "            #extracting all columns\n",
    "        team_ranking= row.find_all('td')\n",
    "        \n",
    "            #strip() to remove extra spaces in string\n",
    "        cols=[x.text.strip() for x in team_ranking] \n",
    "        \n",
    "        #adding data to dictionary\n",
    "        team_details['Team_ranking'].append(cols[0])\n",
    "        #replacing \\n in name by space\n",
    "        team_details['Team_name'].append((cols[1]).replace('\\n' ,' '))\n",
    "        team_details['Matches'].append(cols[2])\n",
    "        team_details['Points'].append(cols[3])\n",
    "        team_details['Ratings'].append(cols[4])\n",
    "\n",
    "        #print(team_details)\n",
    "df=pd.DataFrame(team_details )\n",
    "print(df)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "436cde38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 ODI Batsmen along with the records of their team and rating.\n",
      "   \n",
      "  POS                 PLAYER TEAM RATING           CAREER BEST RATING\n",
      "0   1             Babar Azam  PAK    873    873 v England, 13/07/2021\n",
      "1   2            Virat Kohli  IND    811    911 v England, 12/07/2018\n",
      "2   3           Rohit Sharma  IND    791  885 v Sri Lanka, 06/07/2019\n",
      "3   4        Quinton de Kock   SA    783  813 v Sri Lanka, 10/03/2019\n",
      "4   5            Aaron Finch  AUS    779    798 v England, 25/06/2019\n",
      "5   6         Jonny Bairstow  ENG    775      796 v India, 26/03/2021\n",
      "6   7           David Warner  AUS    762   880 v Pakistan, 26/01/2017\n",
      "7   8  Rassie van der Dussen   SA    750      750 v India, 23/01/2022\n",
      "8   9           Fakhar Zaman  PAK    741    779 v England, 08/07/2021\n",
      "9  10               Joe Root  ENG    740  824 v Sri Lanka, 13/10/2018\n"
     ]
    }
   ],
   "source": [
    "#\"5.b) Top 10 ODI Batsmen along with the records of their team and rating.\n",
    "print(\"Top 10 ODI Batsmen along with the records of their team and rating.\")\n",
    "print(\"   \")\n",
    "\n",
    "url = 'https://www.icc-cricket.com/rankings/mens/player-rankings/ODI/batting'\n",
    "bat= requests.get(url)\n",
    "\n",
    "Batsman_details={'POS' :[],\n",
    "               'PLAYER' :[],\n",
    "                'TEAM' :[],\n",
    "                'RATING' :[],\n",
    "                'CAREER BEST RATING' :[]}\n",
    "\n",
    "\n",
    "soup=BeautifulSoup(bat.text, 'html.parser')\n",
    "\n",
    "data=soup.find('table',class_='table')\n",
    "rows=data.find_all('tr')\n",
    "for row in rows[1:11]:\n",
    "    player_ranking = row.find_all('td')\n",
    "    cols=[x.text.strip() for x in player_ranking]\n",
    " \n",
    "    Batsman_details['POS'].append(cols[0])\n",
    "                                  \n",
    "    Batsman_details['PLAYER'].append(cols[1])\n",
    "    Batsman_details['TEAM'].append(cols[2])\n",
    "    Batsman_details['RATING'].append(cols[3])\n",
    "    Batsman_details['CAREER BEST RATING'].append(cols[4])\n",
    "    \n",
    "df=pd.DataFrame(Batsman_details)\n",
    "\n",
    "## to format string 1\\n\\n\\n --> 1 \n",
    "\n",
    "df[\"POS\"]=df[\"POS\"].str[:2]\n",
    "df[\"POS\"]=df[\"POS\"].replace('\\n','',regex=True) \n",
    "print(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2ca1ee6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>POS</th>\n",
       "      <th>PLAYER</th>\n",
       "      <th>TEAM</th>\n",
       "      <th>RATING</th>\n",
       "      <th>CAREER BEST RATING</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Trent Boult</td>\n",
       "      <td>NZ</td>\n",
       "      <td>737</td>\n",
       "      <td>770 v West Indies, 22/06/2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Josh Hazlewood</td>\n",
       "      <td>AUS</td>\n",
       "      <td>709</td>\n",
       "      <td>733 v England, 26/01/2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Chris Woakes</td>\n",
       "      <td>ENG</td>\n",
       "      <td>700</td>\n",
       "      <td>711 v Sri Lanka, 04/07/2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Matt Henry</td>\n",
       "      <td>NZ</td>\n",
       "      <td>691</td>\n",
       "      <td>691 v Bangladesh, 26/03/2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>Mujeeb Ur Rahman</td>\n",
       "      <td>AFG</td>\n",
       "      <td>681</td>\n",
       "      <td>712 v Ireland, 24/01/2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>Jasprit Bumrah</td>\n",
       "      <td>IND</td>\n",
       "      <td>679</td>\n",
       "      <td>841 v West Indies, 01/11/2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>Mehedi Hasan</td>\n",
       "      <td>BAN</td>\n",
       "      <td>675</td>\n",
       "      <td>725 v Sri Lanka, 25/05/2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>Mitchell Starc</td>\n",
       "      <td>AUS</td>\n",
       "      <td>652</td>\n",
       "      <td>783 v New Zealand, 29/03/2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>Rashid Khan</td>\n",
       "      <td>AFG</td>\n",
       "      <td>650</td>\n",
       "      <td>806 v Pakistan, 21/09/2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>Andy McBrine</td>\n",
       "      <td>IRE</td>\n",
       "      <td>646</td>\n",
       "      <td>646 v West Indies, 16/01/2022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   POS            PLAYER TEAM  RATING             CAREER BEST RATING\n",
       "1    1       Trent Boult    NZ    737  770 v West Indies, 22/06/2019\n",
       "2    2    Josh Hazlewood   AUS    709      733 v England, 26/01/2018\n",
       "3    3      Chris Woakes   ENG    700    711 v Sri Lanka, 04/07/2021\n",
       "4    4        Matt Henry    NZ    691   691 v Bangladesh, 26/03/2021\n",
       "5    5  Mujeeb Ur Rahman   AFG    681      712 v Ireland, 24/01/2021\n",
       "6    6    Jasprit Bumrah   IND    679  841 v West Indies, 01/11/2018\n",
       "7    7      Mehedi Hasan   BAN    675    725 v Sri Lanka, 25/05/2021\n",
       "8    8    Mitchell Starc   AUS    652  783 v New Zealand, 29/03/2015\n",
       "9    9       Rashid Khan   AFG    650     806 v Pakistan, 21/09/2018\n",
       "10  10      Andy McBrine   IRE    646  646 v West Indies, 16/01/2022"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#5.c)\n",
    "\n",
    "url = 'https://www.icc-cricket.com/rankings/mens/player-rankings/odi/bowling'\n",
    "\n",
    "\n",
    "page= requests.get(url)\n",
    "soup=BeautifulSoup(page.text, 'html.parser')\n",
    "table_body =soup.find('table')\n",
    "row_data=[]\n",
    "header_data=[]\n",
    "\n",
    "for row in table_body.find_all('tr'):\n",
    "    cols=row.find_all('td')\n",
    "    col=[ele.text.strip() for ele in cols]\n",
    "\n",
    "    row_data.append(col)\n",
    "for headers in soup.find_all('th'):\n",
    "    header=[headers.text.strip() ]\n",
    "    header_data.append(header)\n",
    "\n",
    "#ValueError: 1 columns passed, passed data had 5 columns getting this\n",
    "#df=pd.DataFrame(row_data,columns=header_data) \n",
    "\n",
    "df=pd.DataFrame(row_data,columns=['POS','PLAYER','TEAM ','RATING','CAREER BEST RATING'])\n",
    "df[\"POS\"]=df[\"POS\"].str[:2]\n",
    "df[\"POS\"]=df[\"POS\"].replace('\\n','',regex=True) \n",
    "df=df.dropna()\n",
    "df.head(10)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a70587",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "273d61fe",
   "metadata": {},
   "source": [
    "# 6) Write a python program to scrape cricket rankings from icc-cricket.com. You have to scrape:\n",
    "a) Top 10 ODI teams in women’s cricket along with the records for matches, points and rating.\n",
    "b) Top 10 women’s ODI Batting players along with the records of their team and rating.\n",
    "c) Top 10 women’s ODI all-rounder along with the records of their team and rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0e72dc78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pos</th>\n",
       "      <th>Team</th>\n",
       "      <th>Matches</th>\n",
       "      <th>Points</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Australia  AUS</td>\n",
       "      <td>20</td>\n",
       "      <td>3,263</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>South Africa  SA</td>\n",
       "      <td>21</td>\n",
       "      <td>2,580</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>England  ENG</td>\n",
       "      <td>21</td>\n",
       "      <td>2,474</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>India  IND</td>\n",
       "      <td>22</td>\n",
       "      <td>2,221</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>New Zealand  NZ</td>\n",
       "      <td>24</td>\n",
       "      <td>2,342</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>Bangladesh  BAN</td>\n",
       "      <td>5</td>\n",
       "      <td>475</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>West Indies  WI</td>\n",
       "      <td>21</td>\n",
       "      <td>1,801</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>Pakistan  PAK</td>\n",
       "      <td>19</td>\n",
       "      <td>1,304</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>Ireland  IRE</td>\n",
       "      <td>5</td>\n",
       "      <td>240</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>Sri Lanka  SL</td>\n",
       "      <td>5</td>\n",
       "      <td>233</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pos              Team Matches Points Rating\n",
       "1    1    Australia  AUS      20  3,263    163\n",
       "2    2  South Africa  SA      21  2,580    123\n",
       "3    3      England  ENG      21  2,474    118\n",
       "4    4        India  IND      22  2,221    101\n",
       "5    5   New Zealand  NZ      24  2,342     98\n",
       "6    6   Bangladesh  BAN       5    475     95\n",
       "7    7   West Indies  WI      21  1,801     86\n",
       "8    8     Pakistan  PAK      19  1,304     69\n",
       "9    9      Ireland  IRE       5    240     48\n",
       "10  10     Sri Lanka  SL       5    233     47"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#6.a) Top 10 ODI teams in women’s cricket along with the records for matches, points and rating.\n",
    "url='https://www.icc-cricket.com/rankings/womens/team-rankings/odi'\n",
    "page= requests.get(url)\n",
    "soup = BeautifulSoup(page.text, \"html.parser\")\n",
    "table_body =soup.find('table')\n",
    "row_data=[]\n",
    "header_data=[]\n",
    "i=0\n",
    "for row in table_body.find_all('tr'):\n",
    "    cols=row.find_all('td')\n",
    "    col=[ele.text.strip() for ele in cols]\n",
    "    \n",
    "    \n",
    "    row_data.append(col)\n",
    "for headers in soup.find_all('th'):\n",
    "    header=[headers.text.strip() ]\n",
    "    header_data.append(header)\n",
    "\n",
    "#ValueError: 1 columns passed, passed data had 5 columns getting this\n",
    "#df=pd.DataFrame(row_data,columns=header_data) \n",
    "\n",
    "df=pd.DataFrame(row_data,columns=['Pos','Team','Matches','Points','Rating'])\n",
    "df=df.replace('\\n','  ',regex=True)\n",
    "df2=df.dropna()\n",
    "df2.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f3c50820",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pos</th>\n",
       "      <th>Player</th>\n",
       "      <th>Team</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Alyssa Healy</td>\n",
       "      <td>AUS</td>\n",
       "      <td>749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2                                        (0)</td>\n",
       "      <td>Mithali Raj</td>\n",
       "      <td>IND</td>\n",
       "      <td>735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3                                            (...</td>\n",
       "      <td>Tammy Beaumont</td>\n",
       "      <td>ENG</td>\n",
       "      <td>707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4                                            (...</td>\n",
       "      <td>Meg Lanning</td>\n",
       "      <td>AUS</td>\n",
       "      <td>706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5                                            (...</td>\n",
       "      <td>Beth Mooney</td>\n",
       "      <td>AUS</td>\n",
       "      <td>705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6                                            (...</td>\n",
       "      <td>Lizelle Lee</td>\n",
       "      <td>SA</td>\n",
       "      <td>702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7                                            (...</td>\n",
       "      <td>Amy Satterthwaite</td>\n",
       "      <td>NZ</td>\n",
       "      <td>700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8                                             ...</td>\n",
       "      <td>Smriti Mandhana</td>\n",
       "      <td>IND</td>\n",
       "      <td>666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9                                            (...</td>\n",
       "      <td>Laura Wolvaardt</td>\n",
       "      <td>SA</td>\n",
       "      <td>661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10                                            ...</td>\n",
       "      <td>Ellyse Perry</td>\n",
       "      <td>AUS</td>\n",
       "      <td>661</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Pos             Player Team  \\\n",
       "0                                                   1       Alyssa Healy  AUS   \n",
       "2        2                                        (0)        Mithali Raj  IND   \n",
       "3   3                                            (...     Tammy Beaumont  ENG   \n",
       "4   4                                            (...        Meg Lanning  AUS   \n",
       "5   5                                            (...        Beth Mooney  AUS   \n",
       "6   6                                            (...        Lizelle Lee   SA   \n",
       "7   7                                            (...  Amy Satterthwaite   NZ   \n",
       "8   8                                             ...    Smriti Mandhana  IND   \n",
       "9   9                                            (...    Laura Wolvaardt   SA   \n",
       "10  10                                            ...       Ellyse Perry  AUS   \n",
       "\n",
       "   Rating  \n",
       "0     749  \n",
       "2     735  \n",
       "3     707  \n",
       "4     706  \n",
       "5     705  \n",
       "6     702  \n",
       "7     700  \n",
       "8     666  \n",
       "9     661  \n",
       "10    661  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#6. b) Top 10 women’s ODI Batting players along with the records of their team and rating. \n",
    "url='https://www.icc-cricket.com/rankings/womens/player-rankings/odi'\n",
    "page= requests.get(url)\n",
    "soup = BeautifulSoup(page.text, \"html.parser\")\n",
    "table_body =soup.find('table')\n",
    "row_data=[]\n",
    "header_data=[]\n",
    "\n",
    "row_data_1=[] #to save 1st palyer data\n",
    "row_data_1_rank=soup.find('span',class_='rankings-block__pos-number').text\n",
    "\n",
    "\n",
    "row_data_1_name=soup.find('div',class_='rankings-block__banner--name').text\n",
    "\n",
    "row_data_1_team=soup.find('div',class_='rankings-block__banner--nationality').text\n",
    "\n",
    "row_data_1.append(row_data_1_rank.strip())\n",
    "row_data_1.append(row_data_1_name.strip())\n",
    "team_rate=row_data_1_team.split()\n",
    "\n",
    "row_data_1.append(team_rate[0])\n",
    "row_data_1.append(team_rate[1])\n",
    "\n",
    "row_data.append(row_data_1)\n",
    "\n",
    "for row in table_body.find_all('tr'):\n",
    "    cols=row.find_all('td')\n",
    "    col=[ele.text.strip() for ele in cols]\n",
    "    \n",
    "    row_data.append(col)\n",
    "for headers in soup.find_all('th'):\n",
    "    header=[headers.text.strip() ]\n",
    "    header_data.append(header)\n",
    "\n",
    "#ValueError: 1 columns passed, passed data had 5 columns getting this\n",
    "#df=pd.DataFrame(row_data,columns=header_data) \n",
    "\n",
    "df=pd.DataFrame(row_data,columns=['Pos','Player','Team','Rating'])\n",
    "df=df.replace('\\n','  ',regex=True)\n",
    "df2=df.dropna()\n",
    "df2.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "78d1f13c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Pos           Player Team Rating\n",
      "0       1      EllysePerry  AUS    749\n",
      "2    2(0)    NatalieSciver  ENG    351\n",
      "3    3(0)    MarizanneKapp   SA    327\n",
      "4    4(1)       AmeliaKerr   NZ    312\n",
      "5    5(1)     DeeptiSharma  IND    309\n",
      "6    6(0)   KatherineBrunt  ENG    273\n",
      "7    7(0)     JessJonassen  AUS    263\n",
      "8    8(0)   StafanieTaylor   WI    262\n",
      "9    9(0)  AshleighGardner  AUS    256\n",
      "10  10(0)   HayleyMatthews   WI    254\n"
     ]
    }
   ],
   "source": [
    "#6.c) Top 10 women’s ODI all-rounder along with the records of their team and rating\n",
    "\n",
    "\n",
    "url='https://www.icc-cricket.com/rankings/womens/player-rankings/odi'\n",
    "page= requests.get(url)\n",
    "soup = BeautifulSoup(page.text, \"html.parser\")\n",
    "container=soup.find('div' , attrs={'data-title':\"ODI All-Rounder Rankings\" } )\n",
    "\n",
    "table_body =container.find('table')\n",
    "\n",
    "\n",
    "row_data=[]\n",
    "header_data=[]\n",
    "\n",
    "row_data_1=[] #to save 1st palyer dat\n",
    "\n",
    "row_data_1_rank=container.find('span',class_='rankings-block__pos-number').text\n",
    "row_data_1_name=container.find('div',class_='rankings-block__banner--name').text\n",
    "row_data_1.append(row_data_1_rank.strip())\n",
    "row_data_1.append(row_data_1_name.strip())\n",
    "\n",
    "row_data_1_team=container.find('div',class_='rankings-block__banner--nationality').text\n",
    "\n",
    "row_data_1.append(team_rate[0])\n",
    "row_data_1.append(team_rate[1])\n",
    "\n",
    "row_data.append(row_data_1)\n",
    "i=0\n",
    "for row in table_body.find_all('tr'):\n",
    "    i=i+1\n",
    "    cols=row.find_all('td')\n",
    "    col=[ele.text.strip() for ele in cols]\n",
    "    y=[]\n",
    "    for x in col:\n",
    "        if \"This player has moved up\" in x:\n",
    "            x=x.replace('This player has moved up in the rankings since the previous rankings update','')\n",
    "        elif 'This player has moved down' in x:\n",
    "            x=x.replace('This player has moved down in the rankings since the previous rankings update','')\n",
    "        y.append(x)    \n",
    "       \n",
    "    row_data.append(y)\n",
    "\n",
    "for headers in soup.find_all('th'):\n",
    "    header=[headers.text.strip()]\n",
    "    header_data.append(header)\n",
    "   \n",
    "# ValueError: 1 columns passed, passed data had 5 columns getting this\n",
    "#df=pd.DataFrame(row_data,columns=header_data) \n",
    "# del row_data[1]\n",
    "\n",
    "df=pd.DataFrame(row_data,columns=['Pos','Player','Team','Rating'])\n",
    "df=df.replace('\\n' ,\"\" ,regex=True)\n",
    "df=df.replace(' ' ,\"\" ,regex=True)\n",
    "print(df.dropna())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6263715c",
   "metadata": {},
   "source": [
    "# 7) Write a python program to scrape details of all the posts from coreyms.com. Scrape the heading, date, content\n",
    "and the code for the video from the link for the youtube video from the post."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "be25ecdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Heading</th>\n",
       "      <th>Date</th>\n",
       "      <th>Content</th>\n",
       "      <th>Link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Python Tutorial: Zip Files – Creating and Extr...</td>\n",
       "      <td>November 19, 2019</td>\n",
       "      <td>In this video, we will be learning how to crea...</td>\n",
       "      <td>https://www.youtube.com/embed/z0gguhEmWiY?vers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Python Data Science Tutorial: Analyzing the 20...</td>\n",
       "      <td>October 17, 2019</td>\n",
       "      <td>In this Python Programming video, we will be l...</td>\n",
       "      <td>https://www.youtube.com/embed/_P7X8tMplsw?vers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Python Multiprocessing Tutorial: Run Code in P...</td>\n",
       "      <td>September 21, 2019</td>\n",
       "      <td>In this Python Programming video, we will be l...</td>\n",
       "      <td>https://www.youtube.com/embed/fKl2JW_qrso?vers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Python Threading Tutorial: Run Code Concurrent...</td>\n",
       "      <td>September 12, 2019</td>\n",
       "      <td>In this Python Programming video, we will be l...</td>\n",
       "      <td>https://www.youtube.com/embed/IEEhzQoKtQU?vers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Update (2019-09-03)</td>\n",
       "      <td>September 3, 2019</td>\n",
       "      <td>Hey everyone. I wanted to give you an update o...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Python Quick Tip: The Difference Between “==” ...</td>\n",
       "      <td>August 6, 2019</td>\n",
       "      <td>In this Python Programming Tutorial, we will b...</td>\n",
       "      <td>https://www.youtube.com/embed/mO_dS3rXDIs?vers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Python Tutorial: Calling External Commands Usi...</td>\n",
       "      <td>July 24, 2019</td>\n",
       "      <td>In this Python Programming Tutorial, we will b...</td>\n",
       "      <td>https://www.youtube.com/embed/2Fp1N6dof0Y?vers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Visual Studio Code (Windows) – Setting up a Py...</td>\n",
       "      <td>May 1, 2019</td>\n",
       "      <td>In this Python Programming Tutorial, we will b...</td>\n",
       "      <td>https://www.youtube.com/embed/-nh9rCzPJ20?vers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Visual Studio Code (Mac) – Setting up a Python...</td>\n",
       "      <td>May 1, 2019</td>\n",
       "      <td>In this Python Programming Tutorial, we will b...</td>\n",
       "      <td>https://www.youtube.com/embed/06I63_p-2A4?vers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Clarifying the Issues with Mutable Default Arg...</td>\n",
       "      <td>April 24, 2019</td>\n",
       "      <td>In this Python Programming Tutorial, we will b...</td>\n",
       "      <td>https://www.youtube.com/embed/_JGmemuINww?vers...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Heading                Date  \\\n",
       "0  Python Tutorial: Zip Files – Creating and Extr...   November 19, 2019   \n",
       "1  Python Data Science Tutorial: Analyzing the 20...    October 17, 2019   \n",
       "2  Python Multiprocessing Tutorial: Run Code in P...  September 21, 2019   \n",
       "3  Python Threading Tutorial: Run Code Concurrent...  September 12, 2019   \n",
       "4                                Update (2019-09-03)   September 3, 2019   \n",
       "5  Python Quick Tip: The Difference Between “==” ...      August 6, 2019   \n",
       "6  Python Tutorial: Calling External Commands Usi...       July 24, 2019   \n",
       "7  Visual Studio Code (Windows) – Setting up a Py...         May 1, 2019   \n",
       "8  Visual Studio Code (Mac) – Setting up a Python...         May 1, 2019   \n",
       "9  Clarifying the Issues with Mutable Default Arg...      April 24, 2019   \n",
       "\n",
       "                                             Content  \\\n",
       "0  In this video, we will be learning how to crea...   \n",
       "1  In this Python Programming video, we will be l...   \n",
       "2  In this Python Programming video, we will be l...   \n",
       "3  In this Python Programming video, we will be l...   \n",
       "4  Hey everyone. I wanted to give you an update o...   \n",
       "5  In this Python Programming Tutorial, we will b...   \n",
       "6  In this Python Programming Tutorial, we will b...   \n",
       "7  In this Python Programming Tutorial, we will b...   \n",
       "8  In this Python Programming Tutorial, we will b...   \n",
       "9  In this Python Programming Tutorial, we will b...   \n",
       "\n",
       "                                                Link  \n",
       "0  https://www.youtube.com/embed/z0gguhEmWiY?vers...  \n",
       "1  https://www.youtube.com/embed/_P7X8tMplsw?vers...  \n",
       "2  https://www.youtube.com/embed/fKl2JW_qrso?vers...  \n",
       "3  https://www.youtube.com/embed/IEEhzQoKtQU?vers...  \n",
       "4                                                     \n",
       "5  https://www.youtube.com/embed/mO_dS3rXDIs?vers...  \n",
       "6  https://www.youtube.com/embed/2Fp1N6dof0Y?vers...  \n",
       "7  https://www.youtube.com/embed/-nh9rCzPJ20?vers...  \n",
       "8  https://www.youtube.com/embed/06I63_p-2A4?vers...  \n",
       "9  https://www.youtube.com/embed/_JGmemuINww?vers...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "          \n",
    "\n",
    "post_details ={'Heading':[],\n",
    "                'Date':[],\n",
    "                'Content':[],\n",
    "                'Link':[]}\n",
    "url=' https://www.coreyms.com.'\n",
    "page = requests.get(url)\n",
    "soup=BeautifulSoup(page.text,'html.parser')\n",
    "\n",
    "# ={'Heading':[]}\n",
    "\n",
    "page_data=soup.find_all('header',class_=\"entry-header\")\n",
    "for x in page_data:\n",
    "#extracting heading\n",
    "    heading=x.find('h2',class_='entry-title').text\n",
    "    post_details['Heading'].append(heading)\n",
    "    \n",
    "#extracting date\n",
    "    date=x.find('time',class_='entry-time').text\n",
    "    post_details['Date'].append(date)\n",
    "\n",
    "page_content=soup.find_all('div', class_= 'entry-content')\n",
    " #to extract content\n",
    "L=0\n",
    "for i in page_content:\n",
    "    L=L+1\n",
    "    content=i.find('p').text\n",
    "    post_details['Content'].append(content)\n",
    "    \n",
    "#to extract video link\n",
    "#since 5th link is not present it shows none to skip 5th n iterate rest will have to enter blank string bcoz length of all sets has to be same in dict.\n",
    "    if(L==5):\n",
    "        link=\"\"\n",
    "        post_details['Link'].append(link)\n",
    "        continue\n",
    "    link=i.find('iframe' ,class_=\"youtube-player\").get('src')\n",
    "    post_details['Link'].append(link)\n",
    "   # print(link)\n",
    "    \n",
    "\n",
    "\n",
    "df =pd.DataFrame(post_details)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a09b0f61",
   "metadata": {},
   "source": [
    "# 8) Write a python program to scrape house details from mentioned URL. It should include house title, location,\n",
    "area, EMI and price from https://www.nobroker.in/ .Enter three localities which are Indira Nagar, Jayanagar, \n",
    "Rajaji Nagar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a4f95ee5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Area</th>\n",
       "      <th>EMI</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1 BHK Flat  For Sale  In Priyadarshani Housing...</td>\n",
       "      <td>Santnagar, Spine Rd, Near Spine City Mall</td>\n",
       "      <td>485 sqft</td>\n",
       "      <td>16,621/Month</td>\n",
       "      <td>29 Lacs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4+ BHK In Independent House  For Sale  In Spin...</td>\n",
       "      <td>cultureCrust Society</td>\n",
       "      <td>4,741 sqft</td>\n",
       "      <td>2.78 Lacs/Month</td>\n",
       "      <td>4.85 Crores</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1 BHK Flat  For Sale  In Nd Landge Nestworth S...</td>\n",
       "      <td>Near Spine City Mall</td>\n",
       "      <td>650 sqft</td>\n",
       "      <td>22,352/Month</td>\n",
       "      <td>39 Lacs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2 BHK For Sale  In Nd Landge Nestworth Society...</td>\n",
       "      <td>Moshi, Sector 10, MIDC, Bhosari,  near  Spine ...</td>\n",
       "      <td>950 sqft</td>\n",
       "      <td>32,669/Month</td>\n",
       "      <td>57 Lacs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1 BHK Flat  For Sale  In Kulswamini In Moshi</td>\n",
       "      <td>SHOP 30 SPINE CITY MALL SANT NAGAR, Sector No. 9</td>\n",
       "      <td>637 sqft</td>\n",
       "      <td>22,925/Month</td>\n",
       "      <td>40 Lacs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0  1 BHK Flat  For Sale  In Priyadarshani Housing...   \n",
       "1  4+ BHK In Independent House  For Sale  In Spin...   \n",
       "2  1 BHK Flat  For Sale  In Nd Landge Nestworth S...   \n",
       "3  2 BHK For Sale  In Nd Landge Nestworth Society...   \n",
       "4       1 BHK Flat  For Sale  In Kulswamini In Moshi   \n",
       "\n",
       "                                            Location        Area  \\\n",
       "0          Santnagar, Spine Rd, Near Spine City Mall    485 sqft   \n",
       "1                               cultureCrust Society  4,741 sqft   \n",
       "2                               Near Spine City Mall    650 sqft   \n",
       "3  Moshi, Sector 10, MIDC, Bhosari,  near  Spine ...    950 sqft   \n",
       "4   SHOP 30 SPINE CITY MALL SANT NAGAR, Sector No. 9    637 sqft   \n",
       "\n",
       "               EMI        price  \n",
       "0     16,621/Month      29 Lacs  \n",
       "1  2.78 Lacs/Month  4.85 Crores  \n",
       "2     22,352/Month      39 Lacs  \n",
       "3     32,669/Month      57 Lacs  \n",
       "4     22,925/Month      40 Lacs  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url=\"https://www.nobroker.in/property/sale/pune/multiple?searchParam=W3sibGF0IjoxOC42Mjk3ODExLCJsb24iOjczLjc5OTcwOTQsInBsYWNlSWQiOiJDaElKcy1xOWZ6ZTR3anNSLUtDbnNkcGxRaXciLCJwbGFjZU5hbWUiOiJQaW1wcmktQ2hpbmNod2FkIn0seyJsYXQiOjE4LjU2MDE2NDksImxvbiI6NzMuODAzMTMzNSwicGxhY2VJZCI6IkNoSUp6VUZnT2tpX3dqc1JMVHJmMlg3Z2FOayIsInBsYWNlTmFtZSI6IkF1bmRoIn0seyJsYXQiOjE4LjY1MDM3MTEsImxvbiI6NzMuODM5MzI1MTk5OTk5OTksInBsYWNlSWQiOiJDaElKS2QyZU1mbTV3anNSRnh1ZnZYM2ZFMk0iLCJwbGFjZU5hbWUiOiJTcGluZSBDaXR5IE1hbGwifV0=&radius=2.0&city=pune&locality=Pimpri-Chinchwad,&locality=Aundh,&locality=Spine%20City%20Mall\"\n",
    "page=requests.get(url)\n",
    "soup = BeautifulSoup(page.text,\"html.parser\")\n",
    "\n",
    "Property_details={'Title':[],\n",
    "                 'Location':[],\n",
    "                 'Area':[],\n",
    "                 'EMI':[],\n",
    "                 'price':[]}\n",
    "# extracting Title\n",
    "titles= soup.find_all('span',class_=\"overflow-hidden overflow-ellipsis whitespace-nowrap max-w-80pe po:max-w-full\")\n",
    "for title in titles:\n",
    "    title=title.text.strip()\n",
    "    Property_details['Title'].append(title)\n",
    "\n",
    "\n",
    "# extracting Location\n",
    "\n",
    "locations= soup.find_all('div',class_=\"mt-0.5p overflow-hidden overflow-ellipsis whitespace-nowrap max-w-70 text-gray-light leading-4 po:mb-0 po:max-w-95\")\n",
    "for location in locations:\n",
    "    location=location.text.strip()\n",
    "    Property_details['Location'].append(location)\n",
    "\n",
    "#extracting area\n",
    "ren=soup.find_all('div',{'id':\"minRent\"})\n",
    "print()\n",
    "for areas in ren:\n",
    "    for area in areas.find('div',class_='flex'):\n",
    "        Property_details['Area'].append(area)\n",
    "# extracting EMI\n",
    "emis=soup.find_all('div' ,{'id':'roomType'})\n",
    "for emi in emis:\n",
    "    emi=emi.text.strip()\n",
    "    emi=emi.replace('â\\x82¹','')\n",
    "    Property_details['EMI'].append(emi)\n",
    "# extracting EMI\n",
    "\n",
    "mindp=soup.find_all('div',{'id':\"minDeposit\"})\n",
    "\n",
    "for prices in mindp:\n",
    "    for price in prices.find('span'):\n",
    "        price=price.replace('â¹','')\n",
    "       \n",
    "        if price==\" \" or \"\" :\n",
    "             continue\n",
    "        else:\n",
    "            Property_details['price'].append(price)\n",
    "           \n",
    "Property_details['price']=[i for i in Property_details['price'] if i ]\n",
    "\n",
    "df=pd.DataFrame(Property_details)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fcda600",
   "metadata": {},
   "source": [
    "# 9) Write a python program to scrape mentioned details from dineout.co.in :\n",
    "i) Restaurant name\n",
    "ii) Cuisine\n",
    "iii) Location\n",
    "iv) Ratings\n",
    "v) Image URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "35d42bb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i) Restaurantname is : Greppo Cafe\n",
      "ii) Cuisines offered are : ['North Indian', ' Chinese', ' Continental']\n",
      "iii) Location is :   Sector 61 |  Gurgaon | \n",
      "iv) Restaurent rating is :  4\n",
      "v) Restaurent rating is :  https://im1.dineout.co.in/images/uploads/restaurant/sharpen/1/g/f/p100732-1637733455619dd44f3dbb0.jpg?tr=tr:n-large\n"
     ]
    }
   ],
   "source": [
    "Dineout_details ={'Restaurant name':[],\n",
    "                'Cuisine':[],\n",
    "                'Locationt':[],\n",
    "                'Ratings':[],\n",
    "                'Image URL':[]}\n",
    "url='https://www.dineout.co.in/delhi/greppo-cafe-sector-61-gurgaon-100732'\n",
    "page = requests.get(url)\n",
    "soup=BeautifulSoup(page.text,'html.parser')\n",
    "# extract name\n",
    "Restaurant_name=soup.find('div',class_=\"restnt-details_info\").find('h1').text\n",
    "print('i) Restaurantname is :',Restaurant_name)\n",
    "\n",
    "#extract Cuisines\n",
    "Cuisines=soup.find('div',class_=\"about-info d-flex\").find_all('a')\n",
    "Cuisines_offered=[]\n",
    "for cuisine in Cuisines:\n",
    "    Cuisines_offered.append(cuisine.text)\n",
    "print('ii) Cuisines offered are :',Cuisines_offered)\n",
    "\n",
    "# extract location\n",
    "loc=soup.find('div',class_='restnt-name').find_all('a')\n",
    "location=\"\"\n",
    "for x in loc[0:2]:\n",
    "    location=location+\" \"+ x.text \n",
    "print('iii) Location is : ',location)\n",
    "\n",
    "#extract ratings\n",
    "rating=soup.find('div', class_=\"cursor rest-rating rating-4_5\").text\n",
    "print(\"iv) Restaurent rating is : \" ,rating)\n",
    "\n",
    "#extract image url\n",
    "url=soup.find('img', class_=\"rdp-banner_img\").get('src')\n",
    "print(\"v) Restaurent rating is : \" ,url)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f5d8d0",
   "metadata": {},
   "source": [
    "# 10) Write a python program to scrape first 10 product details which include product name , price , Image URL from\n",
    "https://www.bewakoof.com/women-tshirts?ga_q=tshirts ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6246be86",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Actual Price</th>\n",
       "      <th>Discounted Price</th>\n",
       "      <th>Image URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Climbing pocket panda Half Sleeve Printed T-s...</td>\n",
       "      <td>799</td>\n",
       "      <td>249</td>\n",
       "      <td>https://images.bewakoof.com/t320/climbing-pock...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Expensive Half Sleeve T-Shirt]</td>\n",
       "      <td>699</td>\n",
       "      <td>249</td>\n",
       "      <td>https://images.bewakoof.com/t320/expensive-boy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Not ordinary Half Sleeve Printed T-Shirt]</td>\n",
       "      <td>799</td>\n",
       "      <td>249</td>\n",
       "      <td>https://images.bewakoof.com/t320/not-ordinary-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Wink New Half Sleeve Printed T-Shirt Yellow]</td>\n",
       "      <td>799</td>\n",
       "      <td>249</td>\n",
       "      <td>https://images.bewakoof.com/t320/wink-new-half...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Bugs On A Pocket Half Sleeve Printed T-Shirt(...</td>\n",
       "      <td>799</td>\n",
       "      <td>249</td>\n",
       "      <td>https://images.bewakoof.com/t320/bugs-on-a-poc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[Love Friends Half Sleeve Printed T-Shirt Mete...</td>\n",
       "      <td>799</td>\n",
       "      <td>249</td>\n",
       "      <td>https://images.bewakoof.com/t320/love-friends-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[Goofy Mickey Pocket Half Sleeve Printed T-Shirt]</td>\n",
       "      <td>799</td>\n",
       "      <td>249</td>\n",
       "      <td>https://images.bewakoof.com/t320/goofy-mickey-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[Chibi Harry Half Sleeve T-Shirt (HPL)]</td>\n",
       "      <td>799</td>\n",
       "      <td>249</td>\n",
       "      <td>https://images.bewakoof.com/t320/chibi-harry-h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[Chibi Friends (FRL) Half Sleeve Printed T-shirt]</td>\n",
       "      <td>799</td>\n",
       "      <td>249</td>\n",
       "      <td>https://images.bewakoof.com/t320/chibi-friends...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[Minimal Believe Boyfriend T-Shirt]</td>\n",
       "      <td>799</td>\n",
       "      <td>249</td>\n",
       "      <td>https://images.bewakoof.com/t320/minimal-belie...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Name Actual Price  \\\n",
       "0  [Climbing pocket panda Half Sleeve Printed T-s...          799   \n",
       "1                    [Expensive Half Sleeve T-Shirt]          699   \n",
       "2         [Not ordinary Half Sleeve Printed T-Shirt]          799   \n",
       "3      [Wink New Half Sleeve Printed T-Shirt Yellow]          799   \n",
       "4  [Bugs On A Pocket Half Sleeve Printed T-Shirt(...          799   \n",
       "5  [Love Friends Half Sleeve Printed T-Shirt Mete...          799   \n",
       "6  [Goofy Mickey Pocket Half Sleeve Printed T-Shirt]          799   \n",
       "7            [Chibi Harry Half Sleeve T-Shirt (HPL)]          799   \n",
       "8  [Chibi Friends (FRL) Half Sleeve Printed T-shirt]          799   \n",
       "9                [Minimal Believe Boyfriend T-Shirt]          799   \n",
       "\n",
       "  Discounted Price                                          Image URL  \n",
       "0              249  https://images.bewakoof.com/t320/climbing-pock...  \n",
       "1              249  https://images.bewakoof.com/t320/expensive-boy...  \n",
       "2              249  https://images.bewakoof.com/t320/not-ordinary-...  \n",
       "3              249  https://images.bewakoof.com/t320/wink-new-half...  \n",
       "4              249  https://images.bewakoof.com/t320/bugs-on-a-poc...  \n",
       "5              249  https://images.bewakoof.com/t320/love-friends-...  \n",
       "6              249  https://images.bewakoof.com/t320/goofy-mickey-...  \n",
       "7              249  https://images.bewakoof.com/t320/chibi-harry-h...  \n",
       "8              249  https://images.bewakoof.com/t320/chibi-friends...  \n",
       "9              249  https://images.bewakoof.com/t320/minimal-belie...  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product_details = {'Name':[],\n",
    "                   'Actual Price':[],\n",
    "                   'Discounted Price':[],\n",
    "                    'Image URL':[]}\n",
    "\n",
    "url='https://www.bewakoof.com/women-tshirts?ga_q=tshirts'\n",
    "page=requests.get(url)\n",
    "soup=BeautifulSoup(page.text , 'html.parser')\n",
    "\n",
    "data =soup.find_all('div',class_='productCardDetail')\n",
    "#print(data)\n",
    "img=soup.find('div', class_ ='productCardImg false')\n",
    "\n",
    "for product in data[0:11]:\n",
    "   \n",
    "#extract product name\n",
    "    name=product.find('h3')\n",
    "   \n",
    "    product_details['Name'].append(name)\n",
    "   \n",
    "\n",
    "#extract product  Actual_price\n",
    "    Actual_price=product.find('span',class_='actualPriceText').text\n",
    "    product_details['Actual Price'].append(Actual_price)\n",
    "    \n",
    "#extract product  Actual_price\n",
    "    dis_price=product.find('span',class_='discountedPriceText')\n",
    "    discounted_price =dis_price.find('b').text\n",
    "    product_details['Discounted Price'].append(discounted_price)\n",
    "    \n",
    "#extract product  Actual_price   \n",
    "img=soup.find_all('div', class_ ='productCardImg false')\n",
    "for image in img[0:11]:\n",
    "    url=image.find('img').get('src')\n",
    "    product_details['Image URL'].append(url)\n",
    "    \n",
    "df =pd.DataFrame(product_details)\n",
    "df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f90605",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
